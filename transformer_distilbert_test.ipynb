{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7874d3e4",
      "metadata": {
        "id": "7874d3e4"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "EGzS501dn0Yn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGzS501dn0Yn",
        "outputId": "bd409a28-417f-464f-fcfd-838692afa4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.8/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.8/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.12.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.8/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.8/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.8/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.8/dist-packages (2022.2.1)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from dask) (6.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask) (2023.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from dask) (23.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask) (0.12.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask) (1.3.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install dask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RowLMImEArzw",
        "outputId": "6811fe8d-17d8-4d75-e9a5-2d4223ec5ad4"
      },
      "id": "RowLMImEArzw",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.22.4)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (4.4.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.3.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from googletrans import Translator # use version 4.0.0-rc1\n",
        "from dask import bag, diagnostics\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.flow as naf"
      ],
      "metadata": {
        "id": "bk9xhiGtAORM"
      },
      "id": "bk9xhiGtAORM",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import math\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LwMYdzwAQJb",
        "outputId": "b00f7933-7dc1-4d06-8f59-b94ca403b121"
      },
      "id": "7LwMYdzwAQJb",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "id": "h4WpZx0hARKR"
      },
      "id": "h4WpZx0hARKR",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # remove single quotes\n",
        "    text = re.sub(r'\\'', '', text)\n",
        "    # remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # remove new lines\n",
        "    text = re.sub(r'   ', ' ', text)\n",
        "    # remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # lower case\n",
        "    text = text.lower()\n",
        "    # remove stop words\n",
        "    # text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    # lemmatize\n",
        "    # lemmatizer = WordNetLemmatizer()\n",
        "    # text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(path, col_names):\n",
        "\n",
        "    original_data=[]\n",
        "\n",
        "    with open (path) as data:\n",
        "        for line in data:\n",
        "            original_data.append(line)\n",
        "            \n",
        "    print('The original data contains ', len(original_data), ' lines.')\n",
        "    \n",
        "    lines = []\n",
        "\n",
        "    for line in original_data:\n",
        "        elements=line.strip().split('\\t')\n",
        "        lines.append(elements)\n",
        "    \n",
        "    df = pd.DataFrame(lines, columns = col_names)\n",
        "\n",
        "    # remove the 0-3 rows since they don't contain any data\n",
        "    df = df.iloc[4:].reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_ids(path):\n",
        "    ids = []\n",
        "    num_lines = 0\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            if num_lines == 0:\n",
        "                num_lines += 1\n",
        "                continue\n",
        "            string = line.strip().split('\\t')[0]\n",
        "            ## get the number at the start of the string\n",
        "            string = int(string.split(',')[0])\n",
        "\n",
        "            ids.append(string)\n",
        "    return ids\n",
        "\n",
        "def preprocess_data(data_folder):\n",
        "    pcl_cols = [\"par_id\", \"art_id\", \"keyword\", \"country_code\", \"text\", \"label\"]\n",
        "    pcl_df = load_and_preprocess_data(f\"{data_folder}/dontpatronizeme_pcl.tsv\", pcl_cols)\n",
        "\n",
        "    ## read txt file in the donrpatronizeme folder ignore the first line and get all the ids\n",
        "    train_ids = get_ids(f\"{data_folder}/train_semeval_parids-labels.txt\")\n",
        "    dev_ids = get_ids(f\"{data_folder}/dev_semeval_parids-labels.txt\")\n",
        "\n",
        "    ## get indexes of the ids in the pcl_df\n",
        "\n",
        "    pcl_df['label'] = pcl_df['label'].astype(int)\n",
        "    pcl_df['par_id'] = pcl_df['par_id'].astype(int)\n",
        "\n",
        "    pcl_df[\"class\"] = pcl_df.apply(lambda x: 1 if x[\"label\"] > 1 else 0, axis=1)\n",
        "    pcl_df[\"text\"] = pcl_df['text'].apply(lambda x: preprocess_text(x))\n",
        "\n",
        "    ## divide into train, train_dev, dev after shuffling\n",
        "\n",
        "    train_indexes = pcl_df[pcl_df['par_id'].isin(train_ids)].index\n",
        "    dev_indexes = pcl_df[pcl_df['par_id'].isin(dev_ids)].index\n",
        "\n",
        "    print(pcl_df.dtypes)\n",
        "\n",
        "    train_df = pcl_df.iloc[train_indexes].reset_index(drop=True)\n",
        "    dev_df = pcl_df.iloc[dev_indexes].reset_index(drop=True)\n",
        "\n",
        "    ## divide train into train and train_dev\n",
        "\n",
        "    train_dev_df = train_df.sample(frac=0.2, random_state=42)\n",
        "    train_df = train_df.drop(train_dev_df.index).reset_index(drop=True)\n",
        "\n",
        "    return train_df, train_dev_df, dev_df"
      ],
      "metadata": {
        "id": "hKV4U7wwAS49"
      },
      "id": "hKV4U7wwAS49",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_char_insertion(text):\n",
        "    aug = nac.KeyboardAug()\n",
        "    augmented_text = aug.augment(text)\n",
        "    return augmented_text[0]\n",
        "\n",
        "def random_swap(text):\n",
        "    aug = naw.RandomWordAug(action=\"swap\")\n",
        "    augmented_text = aug.augment(text)\n",
        "    return augmented_text[0]\n",
        "\n",
        "def synonym_replacement(text):\n",
        "    aug = naw.SynonymAug(aug_src='wordnet')\n",
        "    augmented_text = aug.augment(text)\n",
        "    return augmented_text[0]\n",
        "\n",
        "def back_translate(sequence, target_lang):\n",
        "\n",
        "    languages = ['en', 'fr', 'th', 'tr', 'ur', 'ru', 'bg', 'de', 'ar', 'zh-cn', 'hi',\n",
        "                 'sw', 'vi', 'es', 'el']\n",
        "    #instantiate translator\n",
        "    translator = Translator()\n",
        "    \n",
        "    #store original language so we can convert back\n",
        "    org_lang = translator.detect(sequence).lang\n",
        "    print(org_lang)\n",
        "\n",
        "    try:\n",
        "        if org_lang in languages:\n",
        "            #translate to new language and back to original\n",
        "            translated = translator.translate(sequence, dest = target_lang).text\n",
        "            #translate back to original language\n",
        "            translated_back = translator.translate(translated, dest = org_lang).text\n",
        "        \n",
        "            output_sequence = translated_back        \n",
        "        #if detected language not in our list of languages, do nothing\n",
        "        else:\n",
        "            output_sequence = sequence\n",
        "    except:\n",
        "        output_sequence = sequence\n",
        "    \n",
        "    return output_sequence\n",
        "\n",
        "# Applies above define function with Dask\n",
        "def back_translate_parallel(dataset, target_lang):\n",
        "    dataset = dataset.copy()\n",
        "\n",
        "    text_bag = bag.from_sequence(dataset['text'].tolist()).map(back_translate, target_lang)\n",
        "    \n",
        "    with diagnostics.ProgressBar():\n",
        "        text_bag = text_bag.compute()\n",
        "\n",
        "    # Add the translated to a new dataframe\n",
        "    df_augmented = pd.DataFrame({\"text\": text_bag, \"class\": dataset['class']})\n",
        "    return df_augmented"
      ],
      "metadata": {
        "id": "5KQkp-ypAS7S"
      },
      "id": "5KQkp-ypAS7S",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation(pcl_df_train_train):\n",
        "\n",
        "    ## Back translation\n",
        "\n",
        "    for i in range(0,600,100):\n",
        "        pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1].iloc[i:i+100].copy()\n",
        "        pcl_df_train_train_aug.dropna(inplace=True)\n",
        "        pcl_df_train_train_aug = back_translate_parallel(pcl_df_train_train_aug, 'es')\n",
        "\n",
        "        pcl_df_train_train_aug['class'] = 1\n",
        "\n",
        "        pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
        "\n",
        "    for i in range(0,600,100):\n",
        "        pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1].iloc[i:i+100].copy()\n",
        "        pcl_df_train_train_aug.dropna(inplace=True)\n",
        "        pcl_df_train_train_aug = back_translate_parallel(pcl_df_train_train_aug, 'fr')\n",
        "\n",
        "        pcl_df_train_train_aug['class'] = 1\n",
        "\n",
        "        pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)   \n",
        "\n",
        "    ## Synonym replacement \n",
        "\n",
        "    pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1].copy()\n",
        "    pcl_df_train_train_aug['text'] = pcl_df_train_train_aug['text'].apply(lambda x: synonym_replacement(x))\n",
        "    pcl_df_train_train_aug['class'] = 1\n",
        "\n",
        "    pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
        "\n",
        "    ## Random swap\n",
        "\n",
        "    pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1][:400].copy()\n",
        "    pcl_df_train_train_aug['text'] = pcl_df_train_train_aug['text'].apply(lambda x: random_swap(x))\n",
        "    pcl_df_train_train_aug['class'] = 1\n",
        "\n",
        "    pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
        "\n",
        "    ## Random char insertion\n",
        "\n",
        "    # pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1][:1000].copy()\n",
        "    # pcl_df_train_train_aug['text'] = pcl_df_train_train_aug['text'].apply(lambda x: random_char_insertion(x))\n",
        "    # pcl_df_train_train_aug['class'] = 1\n",
        "\n",
        "    # pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
        "\n",
        "    return pcl_df_train_train    "
      ],
      "metadata": {
        "id": "m9MfBP2cAV-n"
      },
      "id": "m9MfBP2cAV-n",
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VztJLjDVBaCl",
        "outputId": "f64ce586-bae4-4395-a060-bbbe47c207e1"
      },
      "id": "VztJLjDVBaCl",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"drive/MyDrive/NLP/dontpatronizeme_v1.4\"\n",
        "train_df, train_dev_df, dev_df = preprocess_data(data_folder)\n",
        "\n",
        "pcl_df_train_train_ = train_df.copy()\n",
        "\n",
        "pcl_df_train_train_ = data_augmentation(pcl_df_train_train_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSU3SCZGAWBP",
        "outputId": "efd4b1c9-0ad3-46df-c099-48b49e8c07ed"
      },
      "id": "bSU3SCZGAWBP",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original data contains  10473  lines.\n",
            "par_id           int64\n",
            "art_id          object\n",
            "keyword         object\n",
            "country_code    object\n",
            "text            object\n",
            "label            int64\n",
            "class            int64\n",
            "dtype: object\n",
            "[########################################] | 100% Completed |  3.9s\n",
            "[########################################] | 100% Completed |  4.1s\n",
            "[########################################] | 100% Completed |  4.1s\n",
            "[########################################] | 100% Completed |  4.9s\n",
            "[########################################] | 100% Completed |  4.5s\n",
            "[########################################] | 100% Completed |  4.0s\n",
            "[########################################] | 100% Completed | 27.9s\n",
            "[########################################] | 100% Completed | 27.8s\n",
            "[########################################] | 100% Completed | 29.0s\n",
            "[########################################] | 100% Completed | 28.3s\n",
            "[########################################] | 100% Completed | 30.1s\n",
            "[########################################] | 100% Completed | 28.9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "whWeAA8FoHbv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whWeAA8FoHbv",
        "outputId": "937f95fc-dd69-4f01-aba3-50e7d487080d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "WORKING_ENV = 'COLAB' # Can be LABS, COLAB or PAPERSPACE\n",
        "\n",
        "assert WORKING_ENV in ['COLAB', 'PAPERSPACE']\n",
        "\n",
        "if WORKING_ENV == 'COLAB':\n",
        "    from google.colab import drive\n",
        "    %load_ext google.colab.data_table\n",
        "    content_path = '/content/drive/MyDrive/'\n",
        "    drive.mount('/content/drive/', force_remount=True) # Outputs will be saved in your google drive\n",
        "\n",
        "else: # Using Paperspace\n",
        "    # Paperspace does not properly render animated progress bars\n",
        "    # Strongly recommend using the JupyterLab UI instead of theirs\n",
        "    !pip install ipywidgets \n",
        "    content_path = '/notebooks'\n",
        "\n",
        "content_path = Path(content_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "-GIs4vKHoQTz",
      "metadata": {
        "id": "-GIs4vKHoQTz"
      },
      "outputs": [],
      "source": [
        "data_folder = f\"{content_path}/NLP/data\"\n",
        "results_folder = f\"{content_path}/NLP/results\"\n",
        "logging_folder = f\"{content_path}/NLP/logs\"\n",
        "\n",
        "# data_folder = f\"{content_path}/data\"\n",
        "# results_folder = f\"{content_path}/results\"\n",
        "# logging_folder = f\"{content_path}/logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "02e75a8e",
      "metadata": {
        "id": "02e75a8e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, LongformerForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c227807c",
      "metadata": {
        "id": "c227807c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import datasets\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1t6BLzd4uWL0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "1t6BLzd4uWL0",
        "outputId": "e1960f48-11ea-4cbd-c618-fb936538d83a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoKfgHrfOFv4",
        "outputId": "d7f763b4-b78d-4989-c5b3-d661e5ec5dbb"
      },
      "id": "ZoKfgHrfOFv4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5dae45",
      "metadata": {
        "id": "fe5dae45"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "cb5cdf4f",
      "metadata": {
        "id": "cb5cdf4f"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train_\n",
        "pcl_df_train_dev = train_dev_df\n",
        "pcl_df_dev =dev_df\n",
        "# pcl_df_dev = pcl_df_dev.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.countplot(x=\"class\", data=pcl_df_train_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "kud0Ryrwg_0m",
        "outputId": "47c79e24-4070-439e-96df-2df759eb34aa"
      },
      "id": "kud0Ryrwg_0m",
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = pd.read_csv(f\"{data_folder}/chatgpt_reword_random_200samples.csv\")"
      ],
      "metadata": {
        "id": "XpMEenphnmDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "c194395a-b6db-48b7-a92d-1917416cb7c5"
      },
      "id": "XpMEenphnmDI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-397-444341f5e9b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatgpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_folder}/chatgpt_reword_random_200samples.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/NLP/data/chatgpt_reword_random_200samples.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt[\"class\"] = 1"
      ],
      "metadata": {
        "id": "kXPoN7uNovOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a36d0807-d3ac-4edf-d394-f9d975fdf842"
      },
      "id": "kXPoN7uNovOu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-398-aa66d62155b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatgpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'chatgpt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train = pcl_df_train_train[[\"text\", \"class\"]].copy()"
      ],
      "metadata": {
        "id": "OS2-izMdoH3s"
      },
      "id": "OS2-izMdoH3s",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCnx35AspTgy",
        "outputId": "3546358e-e6a3-4fa0-ede2-46e0e9576710"
      },
      "id": "SCnx35AspTgy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9525, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "so7vkjtApXEn",
        "outputId": "23f62440-d959-4b4b-9788-943a24983d89"
      },
      "id": "so7vkjtApXEn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-401-38cdf01de961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatgpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'chatgpt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train = pd.concat([pcl_df_train_train, chatgpt], ignore_index=True)"
      ],
      "metadata": {
        "id": "egPVSyV_n7Uq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "eb027db7-538f-40db-9c41-fd998e01dfce"
      },
      "id": "egPVSyV_n7Uq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-402-21055f431c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpcl_df_train_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpcl_df_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchatgpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'chatgpt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFu8wm22pbHL",
        "outputId": "889c0721-567a-4419-9a89-f2456e44e7e5"
      },
      "id": "nFu8wm22pbHL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9525, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pcl_df_train_train = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug.csv\")\n",
        "# pcl_df_train_dev = pd.read_csv(f\"{data_folder}/pcl_df_train_dev_processed.csv\")\n",
        "# pcl_df_dev = pd.read_csv(f\"{data_folder}/pcl_df_dev_processed.csv\")"
      ],
      "metadata": {
        "id": "hpJPNzRggod5"
      },
      "id": "hpJPNzRggod5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "4scOXNqpz7kk",
      "metadata": {
        "id": "4scOXNqpz7kk"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train[['text', 'class']]\n",
        "pcl_df_train_dev = pcl_df_train_dev[['text', 'class']]\n",
        "pcl_df_dev = pcl_df_dev[['text', 'class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "Hjp2v11UsLJG",
      "metadata": {
        "id": "Hjp2v11UsLJG"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = datasets.Dataset.from_pandas(pcl_df_train_train)\n",
        "pcl_df_train_dev = datasets.Dataset.from_pandas(pcl_df_train_dev)\n",
        "pcl_df_dev = datasets.Dataset.from_pandas(pcl_df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "WGdjyeU_pvc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGdjyeU_pvc8",
        "outputId": "1f41178d-040a-4144-b032-f40ac473e330"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "type(pcl_df_train_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed7f0e63",
      "metadata": {
        "id": "ed7f0e63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a583272e",
      "metadata": {
        "id": "a583272e"
      },
      "source": [
        "### DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "fce901dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fce901dd",
        "outputId": "2be8fa91-9743-4dc9-a0ae-f6c295b65cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "97ca230e",
      "metadata": {
        "id": "97ca230e"
      },
      "outputs": [],
      "source": [
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "f2ecf1c8",
      "metadata": {
        "id": "f2ecf1c8"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "c729b6a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c729b6a6",
        "outputId": "a51028eb-b59d-4593-a293-477a664be811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", \n",
        "    num_labels=2, \n",
        "    id2label=id2label, \n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distilbert_model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh9K4xrJX-Pf",
        "outputId": "b454be1f-73cf-4717-b60c-5d4e061396f8"
      },
      "id": "Bh9K4xrJX-Pf",
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=2, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "31e375c1",
      "metadata": {
        "id": "31e375c1"
      },
      "outputs": [],
      "source": [
        "distilbert_model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Linear(768, 64),\n",
        "    torch.nn.BatchNorm1d(64),\n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(64, 2),\n",
        "    torch.nn.Softmax(dim=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c432cb5e",
      "metadata": {
        "id": "c432cb5e"
      },
      "source": [
        "### Functions for Tokenization and Metrics Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "457af8a3",
      "metadata": {
        "id": "457af8a3"
      },
      "outputs": [],
      "source": [
        "tokenizer = distilbert_tokenizer\n",
        "# define a function that will tokenize the model, and will return the relevant \n",
        "# inputs for the model\n",
        "def tokenization(batched_text):\n",
        "    return tokenizer(\n",
        "        batched_text['text'], \n",
        "        padding = 'max_length', \n",
        "        truncation=True, \n",
        "        max_length = 512\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "id": "08036e65",
      "metadata": {
        "id": "08036e65"
      },
      "outputs": [],
      "source": [
        "# define accuracy metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3681358",
      "metadata": {
        "id": "b3681358"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "id": "RBcu4wbjpHrr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c6d33af4ea0548b89ad6e5c51a1a8ab3",
            "170f779e16b54930be93ab0438ee3882",
            "558307df88d945c3b4a03da63673f6c2",
            "e33869ef6efe4c688975df690b632b46",
            "41f37a9e131446bc998efa8cca689a84",
            "b7d834ac4d7645d4899792612b4b1204",
            "32310ea31e054b418df97a317217e75e",
            "770dd1a5c20242709d2cd1e65682dbcd",
            "89e081bff49c4a9a840b5a2b9cf8136a",
            "6c82e848ef4f4b339d125dbee772f528",
            "dea7f2a560a542b18966835bccf57d47",
            "4ffc1672705b4d8ba1150b5ca36d362a",
            "b41bb6725c074f21a9f0a66a91be30cd",
            "54a657b1cd8f459cb3c46a288db5bdae",
            "f0efd73eeecf4db4a4487096b461eca6",
            "27c59b69e5e1420cab30fcbe3641b97a",
            "c9f2a434ad9d4452aed74f9a52405dd4",
            "06fe1d00210c40628042e8724760bb59",
            "3fd15be5eba34f2cb01be2bf356ce8a4",
            "8590df3a39d0483ea01ec2cf376d8f2f",
            "f7786304db5d4a029fc5c9e4c41191ff",
            "2387b892afb6435596db1438224597a3",
            "52eb1d593af845a19a05b89e397fa5b0",
            "4fb711578f5a413981db4037a371dd93",
            "4b591ab9bf9a4eb8baef43b78875bf95",
            "e52aa24bc5e7485ebdbf479c81b789cf",
            "e894c9823b2e4dd8a21ba87ad829fa81",
            "87766a164d6a4c7096d5f18a8296e48a",
            "9cd43f4045f94ea28bb87457bfe9a512",
            "fb6e90e190404e2091accd738a42cdb9",
            "acd25c0969a141888ed928fcce8d6593",
            "96ea51fe17354ac1b3c2db8c7cbe1f46",
            "b4ae41509c1d4a2cae122919f0cc164c"
          ]
        },
        "id": "RBcu4wbjpHrr",
        "outputId": "f3a76147-7c86-4f13-d125-d2a022dba733"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10125 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6d33af4ea0548b89ad6e5c51a1a8ab3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1675 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ffc1672705b4d8ba1150b5ca36d362a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52eb1d593af845a19a05b89e397fa5b0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train)\n",
        ")\n",
        "pcl_df_train_dev = pcl_df_train_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_dev)\n",
        ")\n",
        "\n",
        "pcl_df_dev = pcl_df_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_dev)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "id": "0ef3cd95",
      "metadata": {
        "id": "0ef3cd95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "5d80d7fd-4844-4787-e7bc-32e9f1050ba8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-190-acbfb3fd6e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pcl_df_train_train.set_format(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m pcl_df_train_dev.set_format(\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mset_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m   2389\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2392\u001b[0m                 \u001b[0;34mf\"Columns {list(filter(lambda col: col not in self._data.column_names, columns))} not in the dataset. Current columns in the dataset: {self._data.column_names}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Columns ['class'] not in the dataset. Current columns in the dataset: ['text', 'label', 'input_ids', 'attention_mask']"
          ]
        }
      ],
      "source": [
        "pcl_df_train_train.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "pcl_df_train_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "pcl_df_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "id": "fVfBKVcT79db",
      "metadata": {
        "id": "fVfBKVcT79db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "02a83a68-76c2-4493-a60b-33bb73acffc2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-145a25ad1ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpcl_df_train_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcl_df_train_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpcl_df_train_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcl_df_train_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpcl_df_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcl_df_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mrename_column\u001b[0;34m(self, original_column_name, new_column_name, new_fingerprint)\u001b[0m\n\u001b[1;32m   2059\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moriginal_column_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2062\u001b[0m                 \u001b[0;34mf\"Original column name {original_column_name} not in the dataset. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                 \u001b[0;34mf\"Current columns in the dataset: {dataset._data.column_names}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Original column name class not in the dataset. Current columns in the dataset: ['text', 'label', 'input_ids', 'attention_mask']"
          ]
        }
      ],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.rename_column(\"class\", \"label\")\n",
        "pcl_df_train_dev = pcl_df_train_dev.rename_column(\"class\", \"label\")\n",
        "pcl_df_dev = pcl_df_dev.rename_column(\"class\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "e8abcd96",
      "metadata": {
        "id": "e8abcd96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6d0e1ab7",
      "metadata": {
        "id": "6d0e1ab7"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "id": "4ba3416d",
      "metadata": {
        "id": "4ba3416d"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "train_batch_size = 32\n",
        "eval_batch_size = 32\n",
        "lr = 2e-5\n",
        "num_epochs = 30\n",
        "gradient_accumulation_steps = 8\n",
        "warmup_steps = 200\n",
        "weight_decay = 0.01\n",
        "logging_steps = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "9624ffbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9624ffbc",
        "outputId": "9541e499-1493-4f35-8c5e-1fa0d82895b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = num_epochs,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'distilbert-classification'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "e0557cc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0557cc2",
        "outputId": "89ff6a6f-3073-47c4-f22d-68fd0fbc534d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=distilbert_model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=pcl_df_train_train,\n",
        "    eval_dataset=pcl_df_train_dev\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811df261",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "811df261",
        "outputId": "726fbcc8-7fa2-4ff6-b963-31e04fa5df1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 10125\n",
            "  Num Epochs = 30\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 1170\n",
            "  Number of trainable parameters = 67002946\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   5/1170 00:02 < 14:42, 1.32 it/s, Epoch 0.10/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "405b4eff",
      "metadata": {
        "id": "405b4eff"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cab2a3dc",
      "metadata": {
        "id": "cab2a3dc"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac97c8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ac97c8e",
        "outputId": "c5cf1487-e2df-4740-a0f8-e68420288bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/distilbert\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/distilbert/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/distilbert/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer.save_model(f'{results_folder}/distilbert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f2Aqt-5l7X",
      "metadata": {
        "id": "27f2Aqt-5l7X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "_PZCZgNl5nGp",
      "metadata": {
        "id": "_PZCZgNl5nGp"
      },
      "source": [
        "### Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QcYDjwOI5l96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcYDjwOI5l96",
        "outputId": "027e8cb5-36f6-4873-81e3-7901ba853103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/NLP/results/distilbert/config.json\n",
            "You are using a model of type distilbert to instantiate a model of type longformer. This is not supported for all configurations of models and can yield errors.\n",
            "Model config LongformerConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"attention_window\": 512,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"longformer\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"onnx_export\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"sep_token_id\": 2,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/NLP/results/distilbert/pytorch_model.bin\n",
            "Some weights of the model checkpoint at /content/drive/MyDrive/NLP/results/distilbert were not used when initializing LongformerForSequenceClassification: ['distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'classifier.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'pre_classifier.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'pre_classifier.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'classifier.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias']\n",
            "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/results/distilbert and are newly initialized: ['encoder.layer.8.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'classifier.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.0.attention.self.key_global.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'classifier.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.self.key_global.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.9.attention.self.value_global.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'classifier.out_proj.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.self.value_global.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'classifier.out_proj.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.key_global.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.self.value_global.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.4.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.attention.self.key_global.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key_global.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.attention.self.value_global.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trained_model = LongformerForSequenceClassification.from_pretrained(\n",
        "    f'{results_folder}/distilbert',\n",
        "    num_labels=2, \n",
        "    id2label=id2label, \n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mofGwDpj69jO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "mofGwDpj69jO",
        "outputId": "5a0ca6a7-25c8-46b4-b041-b48727030758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.37963035702705383,\n",
              " 'eval_accuracy': 0.9385074626865672,\n",
              " 'eval_f1': 0.6869300911854104,\n",
              " 'eval_precision': 0.743421052631579,\n",
              " 'eval_recall': 0.6384180790960452,\n",
              " 'eval_runtime': 1.7938,\n",
              " 'eval_samples_per_second': 933.748,\n",
              " 'eval_steps_per_second': 58.533,\n",
              " 'epoch': 9.99}"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1360ef1",
      "metadata": {
        "id": "e1360ef1"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb767e66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "bb767e66",
        "outputId": "c8284b05-c3b7-45e2-c56f-6bfa60a9742f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "dev_set_preds, labels, metrics = trainer.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVM65wl8gK_3",
        "outputId": "30bc6f58-c72a-4f77-ae92-313aeaa5e384"
      },
      "id": "hVM65wl8gK_3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss': 0.4193435311317444,\n",
              " 'dev_accuracy': 0.939799331103679,\n",
              " 'dev_f1': 0.64,\n",
              " 'dev_precision': 0.7417218543046358,\n",
              " 'dev_recall': 0.5628140703517588,\n",
              " 'dev_runtime': 2.4336,\n",
              " 'dev_samples_per_second': 860.041,\n",
              " 'dev_steps_per_second': 53.83}"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1957145",
      "metadata": {
        "id": "d1957145"
      },
      "outputs": [],
      "source": [
        "dev_set_preds = np.argmax(dev_set_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297919af",
      "metadata": {
        "id": "297919af"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6d33af4ea0548b89ad6e5c51a1a8ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_170f779e16b54930be93ab0438ee3882",
              "IPY_MODEL_558307df88d945c3b4a03da63673f6c2",
              "IPY_MODEL_e33869ef6efe4c688975df690b632b46"
            ],
            "layout": "IPY_MODEL_41f37a9e131446bc998efa8cca689a84"
          }
        },
        "170f779e16b54930be93ab0438ee3882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d834ac4d7645d4899792612b4b1204",
            "placeholder": "​",
            "style": "IPY_MODEL_32310ea31e054b418df97a317217e75e",
            "value": "Map: 100%"
          }
        },
        "558307df88d945c3b4a03da63673f6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_770dd1a5c20242709d2cd1e65682dbcd",
            "max": 10125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89e081bff49c4a9a840b5a2b9cf8136a",
            "value": 10125
          }
        },
        "e33869ef6efe4c688975df690b632b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c82e848ef4f4b339d125dbee772f528",
            "placeholder": "​",
            "style": "IPY_MODEL_dea7f2a560a542b18966835bccf57d47",
            "value": " 10125/10125 [00:02&lt;00:00, 4439.39 examples/s]"
          }
        },
        "41f37a9e131446bc998efa8cca689a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b7d834ac4d7645d4899792612b4b1204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32310ea31e054b418df97a317217e75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "770dd1a5c20242709d2cd1e65682dbcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89e081bff49c4a9a840b5a2b9cf8136a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c82e848ef4f4b339d125dbee772f528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea7f2a560a542b18966835bccf57d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ffc1672705b4d8ba1150b5ca36d362a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b41bb6725c074f21a9f0a66a91be30cd",
              "IPY_MODEL_54a657b1cd8f459cb3c46a288db5bdae",
              "IPY_MODEL_f0efd73eeecf4db4a4487096b461eca6"
            ],
            "layout": "IPY_MODEL_27c59b69e5e1420cab30fcbe3641b97a"
          }
        },
        "b41bb6725c074f21a9f0a66a91be30cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f2a434ad9d4452aed74f9a52405dd4",
            "placeholder": "​",
            "style": "IPY_MODEL_06fe1d00210c40628042e8724760bb59",
            "value": "Map: 100%"
          }
        },
        "54a657b1cd8f459cb3c46a288db5bdae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd15be5eba34f2cb01be2bf356ce8a4",
            "max": 1675,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8590df3a39d0483ea01ec2cf376d8f2f",
            "value": 1675
          }
        },
        "f0efd73eeecf4db4a4487096b461eca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7786304db5d4a029fc5c9e4c41191ff",
            "placeholder": "​",
            "style": "IPY_MODEL_2387b892afb6435596db1438224597a3",
            "value": " 1675/1675 [00:00&lt;00:00, 5244.86 examples/s]"
          }
        },
        "27c59b69e5e1420cab30fcbe3641b97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c9f2a434ad9d4452aed74f9a52405dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06fe1d00210c40628042e8724760bb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fd15be5eba34f2cb01be2bf356ce8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8590df3a39d0483ea01ec2cf376d8f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7786304db5d4a029fc5c9e4c41191ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2387b892afb6435596db1438224597a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52eb1d593af845a19a05b89e397fa5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fb711578f5a413981db4037a371dd93",
              "IPY_MODEL_4b591ab9bf9a4eb8baef43b78875bf95",
              "IPY_MODEL_e52aa24bc5e7485ebdbf479c81b789cf"
            ],
            "layout": "IPY_MODEL_e894c9823b2e4dd8a21ba87ad829fa81"
          }
        },
        "4fb711578f5a413981db4037a371dd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87766a164d6a4c7096d5f18a8296e48a",
            "placeholder": "​",
            "style": "IPY_MODEL_9cd43f4045f94ea28bb87457bfe9a512",
            "value": "Map: 100%"
          }
        },
        "4b591ab9bf9a4eb8baef43b78875bf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6e90e190404e2091accd738a42cdb9",
            "max": 2094,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acd25c0969a141888ed928fcce8d6593",
            "value": 2094
          }
        },
        "e52aa24bc5e7485ebdbf479c81b789cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ea51fe17354ac1b3c2db8c7cbe1f46",
            "placeholder": "​",
            "style": "IPY_MODEL_b4ae41509c1d4a2cae122919f0cc164c",
            "value": " 2094/2094 [00:00&lt;00:00, 5292.35 examples/s]"
          }
        },
        "e894c9823b2e4dd8a21ba87ad829fa81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "87766a164d6a4c7096d5f18a8296e48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cd43f4045f94ea28bb87457bfe9a512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb6e90e190404e2091accd738a42cdb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd25c0969a141888ed928fcce8d6593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96ea51fe17354ac1b3c2db8c7cbe1f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ae41509c1d4a2cae122919f0cc164c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}