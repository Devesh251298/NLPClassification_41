{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n",
    "!pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from googletrans import Translator # use version 4.0.0-rc1\n",
    "from dask import bag, diagnostics\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.flow as naf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_char_insertion(text):\n",
    "    aug = nac.KeyboardAug()\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text[0]\n",
    "\n",
    "def random_swap(text):\n",
    "    aug = naw.RandomWordAug(action=\"swap\")\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text[0]\n",
    "\n",
    "def synonym_replacement(text):\n",
    "    aug = naw.SynonymAug(aug_src='wordnet')\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text[0]\n",
    "\n",
    "def back_translate(sequence, target_lang):\n",
    "\n",
    "    languages = ['en', 'fr', 'th', 'tr', 'ur', 'ru', 'bg', 'de', 'ar', 'zh-cn', 'hi',\n",
    "                 'sw', 'vi', 'es', 'el']\n",
    "    #instantiate translator\n",
    "    translator = Translator()\n",
    "    \n",
    "    #store original language so we can convert back\n",
    "    org_lang = translator.detect(sequence).lang\n",
    "\n",
    "    try:\n",
    "        if org_lang in languages:\n",
    "            #translate to new language and back to original\n",
    "            translated = translator.translate(sequence, dest = target_lang).text\n",
    "            #translate back to original language\n",
    "            translated_back = translator.translate(translated, dest = org_lang).text\n",
    "        \n",
    "            output_sequence = translated_back        \n",
    "        #if detected language not in our list of languages, do nothing\n",
    "        else:\n",
    "            output_sequence = sequence\n",
    "    except:\n",
    "        output_sequence = sequence\n",
    "    \n",
    "    return output_sequence\n",
    "\n",
    "# Applies above define function with Dask\n",
    "def back_translate_parallel(dataset, target_lang):\n",
    "    dataset = dataset.copy()\n",
    "    text_bag = bag.from_sequence(dataset['text'].tolist()).map(back_translate, target_lang)\n",
    "    \n",
    "    with diagnostics.ProgressBar():\n",
    "        text_bag = text_bag.compute()\n",
    "\n",
    "    # Add the translated to a new dataframe\n",
    "    df_augmented = pd.DataFrame({\"text\": text_bag, \"class\": dataset['class']})\n",
    "    return df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(pcl_df_train_train):\n",
    "\n",
    "    ## Back translation\n",
    "\n",
    "    for i in range(0,600,100):\n",
    "        pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1].iloc[i:i+100].copy()\n",
    "        pcl_df_train_train_aug.dropna(inplace=True)\n",
    "        pcl_df_train_train_aug = back_translate_parallel(pcl_df_train_train_aug, 'fr')\n",
    "\n",
    "        pcl_df_train_train_aug['class'] = 1\n",
    "\n",
    "        pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
    "\n",
    "    ## Synonym replacement \n",
    "\n",
    "    pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1].copy()\n",
    "    pcl_df_train_train_aug['text'] = pcl_df_train_train_aug['text'].apply(lambda x: synonym_replacement(x))\n",
    "    pcl_df_train_train_aug['class'] = 1\n",
    "\n",
    "    pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
    "\n",
    "    ## Random swap\n",
    "\n",
    "    pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1][:1000].copy()\n",
    "    pcl_df_train_train_aug['text'] = pcl_df_train_train_aug['text'].apply(lambda x: random_swap(x))\n",
    "    pcl_df_train_train_aug['class'] = 1\n",
    "\n",
    "    pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
    "\n",
    "    ## Random char insertion\n",
    "\n",
    "    pcl_df_train_train_aug = pcl_df_train_train[pcl_df_train_train['class'] == 1][:1000].copy()\n",
    "    pcl_df_train_train_aug['text'] = pcl_df_train_train_aug['text'].apply(lambda x: random_char_insertion(x))\n",
    "    pcl_df_train_train_aug['class'] = 1\n",
    "\n",
    "    pcl_df_train_train = pd.concat([pcl_df_train_train, pcl_df_train_train_aug], ignore_index=True)\n",
    "\n",
    "    return pcl_df_train_train    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
