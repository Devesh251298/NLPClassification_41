{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7874d3e4",
      "metadata": {
        "id": "7874d3e4"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "EGzS501dn0Yn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGzS501dn0Yn",
        "outputId": "c9537e67-8879-43da-99bf-9aa8440c6bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: tokenizers, xxhash, dill, responses, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.10.1 dill-0.3.6 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.26.1 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "whWeAA8FoHbv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whWeAA8FoHbv",
        "outputId": "ca92c1b1-1bd1-40a5-b235-717c1603bc07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "WORKING_ENV = 'COLAB' # Can be LABS, COLAB or PAPERSPACE\n",
        "\n",
        "assert WORKING_ENV in ['COLAB', 'PAPERSPACE']\n",
        "\n",
        "if WORKING_ENV == 'COLAB':\n",
        "    from google.colab import drive\n",
        "    %load_ext google.colab.data_table\n",
        "    content_path = '/content/drive/MyDrive/'\n",
        "    drive.mount('/content/drive/', force_remount=True) # Outputs will be saved in your google drive\n",
        "\n",
        "else: # Using Paperspace\n",
        "    # Paperspace does not properly render animated progress bars\n",
        "    # Strongly recommend using the JupyterLab UI instead of theirs\n",
        "    !pip install ipywidgets \n",
        "    content_path = '/notebooks'\n",
        "\n",
        "content_path = Path(content_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "-GIs4vKHoQTz",
      "metadata": {
        "id": "-GIs4vKHoQTz"
      },
      "outputs": [],
      "source": [
        "data_folder = f\"{content_path}/NLP/data\"\n",
        "results_folder = f\"{content_path}/NLP/results\"\n",
        "logging_folder = f\"{content_path}/NLP/logs\"\n",
        "\n",
        "# data_folder = f\"{content_path}/data\"\n",
        "# results_folder = f\"{content_path}/results\"\n",
        "# logging_folder = f\"{content_path}/logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "02e75a8e",
      "metadata": {
        "id": "02e75a8e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, LongformerForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c227807c",
      "metadata": {
        "id": "c227807c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import datasets\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1t6BLzd4uWL0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1t6BLzd4uWL0",
        "outputId": "e47c1271-2c14-437b-c276-d00ac1efa37a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5dae45",
      "metadata": {
        "id": "fe5dae45"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "cb5cdf4f",
      "metadata": {
        "id": "cb5cdf4f"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pd.read_csv(f\"{data_folder}/pcl_df_train_train.csv\")\n",
        "pcl_df_train_dev = pd.read_csv(f\"{data_folder}/pcl_df_train_dev.csv\")\n",
        "pcl_df_dev = pd.read_csv(f\"{data_folder}/pcl_df_dev.csv\")\n",
        "pcl_df_dev = pcl_df_dev.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = pd.read_csv(f\"{data_folder}/chatgpt_reword_random_200samples.csv\")"
      ],
      "metadata": {
        "id": "XpMEenphnmDI"
      },
      "id": "XpMEenphnmDI",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt[\"class\"] = 1"
      ],
      "metadata": {
        "id": "kXPoN7uNovOu"
      },
      "id": "kXPoN7uNovOu",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train = pcl_df_train_train[[\"text\", \"class\"]].copy()"
      ],
      "metadata": {
        "id": "OS2-izMdoH3s"
      },
      "id": "OS2-izMdoH3s",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCnx35AspTgy",
        "outputId": "e91c80ad-6d9a-4a2e-d013-441d5448ede2"
      },
      "id": "SCnx35AspTgy",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6700, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so7vkjtApXEn",
        "outputId": "a4378e0f-381d-4269-9d36-bade53a53590"
      },
      "id": "so7vkjtApXEn",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(198, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train = pd.concat([pcl_df_train_train, chatgpt], ignore_index=True)"
      ],
      "metadata": {
        "id": "egPVSyV_n7Uq"
      },
      "id": "egPVSyV_n7Uq",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_df_train_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFu8wm22pbHL",
        "outputId": "a7ecbf2d-9c98-4592-c4a5-4566177b91f6"
      },
      "id": "nFu8wm22pbHL",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6898, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pcl_df_train_train = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug.csv\")\n",
        "# pcl_df_train_dev = pd.read_csv(f\"{data_folder}/pcl_df_train_dev_processed.csv\")\n",
        "# pcl_df_dev = pd.read_csv(f\"{data_folder}/pcl_df_dev_processed.csv\")"
      ],
      "metadata": {
        "id": "hpJPNzRggod5"
      },
      "id": "hpJPNzRggod5",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "4scOXNqpz7kk",
      "metadata": {
        "id": "4scOXNqpz7kk"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train[['text', 'class']]\n",
        "pcl_df_train_dev = pcl_df_train_dev[['text', 'class']]\n",
        "pcl_df_dev = pcl_df_dev[['text', 'class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "Hjp2v11UsLJG",
      "metadata": {
        "id": "Hjp2v11UsLJG"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = datasets.Dataset.from_pandas(pcl_df_train_train)\n",
        "pcl_df_train_dev = datasets.Dataset.from_pandas(pcl_df_train_dev)\n",
        "pcl_df_dev = datasets.Dataset.from_pandas(pcl_df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "WGdjyeU_pvc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGdjyeU_pvc8",
        "outputId": "577b7127-cd99-4415-ca8f-62bd4b2f1b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "type(pcl_df_train_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ed7f0e63",
      "metadata": {
        "id": "ed7f0e63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a583272e",
      "metadata": {
        "id": "a583272e"
      },
      "source": [
        "### DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "fce901dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fce901dd",
        "outputId": "40c549b2-2d29-41ab-b3b1-a21c255ac097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "97ca230e",
      "metadata": {
        "id": "97ca230e"
      },
      "outputs": [],
      "source": [
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "f2ecf1c8",
      "metadata": {
        "id": "f2ecf1c8"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "c729b6a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c729b6a6",
        "outputId": "fc4a6f89-cb72-4e54-b614-7055952ff739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", \n",
        "    num_labels=2, \n",
        "    id2label=id2label, \n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "31e375c1",
      "metadata": {
        "id": "31e375c1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c432cb5e",
      "metadata": {
        "id": "c432cb5e"
      },
      "source": [
        "### Functions for Tokenization and Metrics Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "457af8a3",
      "metadata": {
        "id": "457af8a3"
      },
      "outputs": [],
      "source": [
        "tokenizer = distilbert_tokenizer\n",
        "# define a function that will tokenize the model, and will return the relevant \n",
        "# inputs for the model\n",
        "def tokenization(batched_text):\n",
        "    return tokenizer(\n",
        "        batched_text['text'], \n",
        "        padding = 'max_length', \n",
        "        truncation=True, \n",
        "        max_length = 512\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "08036e65",
      "metadata": {
        "id": "08036e65"
      },
      "outputs": [],
      "source": [
        "# define accuracy metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3681358",
      "metadata": {
        "id": "b3681358"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "RBcu4wbjpHrr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "eb63528ab0e246d2bce1d3cd4ed4ecf3",
            "67173bddc1504a0a8e78bd46216c580f",
            "2e12f20aee974492b1548dd565fbf4b0",
            "222769494c89412b9f78f5b6257745f4",
            "18b2eea4ed0a4fbb9107647006dee309",
            "c8a01f22876e467bbc126391c2274249",
            "0b3e415e145943208600ba3a2054a2d2",
            "b7d7f9e3d5d94426bfaef5591bcbf196",
            "630281d7488441ad93a0f322b005afaf",
            "8e6731d0dcdb4edf8d8d80ee0408efdd",
            "e46fc16aea294684af0bae4970939cc9",
            "ba9d3bb5705843f9a7a48836f6b89c26",
            "ea4ac2e9666346d59b5ee046bec790db",
            "11a92bcc0b384bf29848e767eb3090b9",
            "65e4e508be1d47d69bcea3509444f014",
            "b39d687f49f74ab495e87373847d4ad5",
            "e6da27b242aa4539a95696ce4095cda6",
            "696a0698dea5417789253eafe46443a1",
            "f9e8abd697a24cc5aff27bc7319ccffe",
            "7f524ec9eaa84d6fbae470a6a356c617",
            "73d621d726274d5a8bd25087c51537c8",
            "450c1708cb434cf989a613d3ca53c761",
            "515d1f1bf8804ee4b4b5746c8b589ab4",
            "f6e54fc57f5a46599882cd951740a3c7",
            "0485d83c10de4407b26e7e65b7f7c36b",
            "10710b9b8df6407eb36cd495168270a6",
            "30438ec707384602968b7d0430a30429",
            "fbe96bf03cac48fdb2857f0e12f45b30",
            "61e8d6754498413a8b98436837ef294a",
            "9643a881f60f4fb9bcc59955b29ffefe",
            "24e08ba53b67435883de524a3986ac43",
            "09e9536eb7e142ab9951d57dd04784d2",
            "c64ac4f5e1e64ef19b6b1aa4f705b9ba"
          ]
        },
        "id": "RBcu4wbjpHrr",
        "outputId": "7289eaa7-3b22-4697-d31d-4ed86d22616c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6898 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb63528ab0e246d2bce1d3cd4ed4ecf3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1675 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba9d3bb5705843f9a7a48836f6b89c26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2093 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "515d1f1bf8804ee4b4b5746c8b589ab4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train)\n",
        ")\n",
        "pcl_df_train_dev = pcl_df_train_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_dev)\n",
        ")\n",
        "\n",
        "pcl_df_dev = pcl_df_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_dev)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "0ef3cd95",
      "metadata": {
        "id": "0ef3cd95"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "pcl_df_train_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "pcl_df_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "fVfBKVcT79db",
      "metadata": {
        "id": "fVfBKVcT79db"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.rename_column(\"class\", \"label\")\n",
        "pcl_df_train_dev = pcl_df_train_dev.rename_column(\"class\", \"label\")\n",
        "pcl_df_dev = pcl_df_dev.rename_column(\"class\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "e8abcd96",
      "metadata": {
        "id": "e8abcd96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6d0e1ab7",
      "metadata": {
        "id": "6d0e1ab7"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "4ba3416d",
      "metadata": {
        "id": "4ba3416d"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "train_batch_size = 8\n",
        "eval_batch_size = 16\n",
        "lr = 2e-5\n",
        "num_epochs = 10\n",
        "gradient_accumulation_steps = 8\n",
        "warmup_steps = 200\n",
        "weight_decay = 0.01\n",
        "logging_steps = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "9624ffbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9624ffbc",
        "outputId": "4f698e3e-a72c-4dd2-cfb7-39968014e9ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = num_epochs,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'distilbert-classification'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "e0557cc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0557cc2",
        "outputId": "e38b3b96-1f34-46d4-dda1-b95fd30e3ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=distilbert_model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=pcl_df_train_train,\n",
        "    eval_dataset=pcl_df_train_dev\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "811df261",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "811df261",
        "outputId": "8b5fd4b6-3e0d-4f3e-e4d6-e8ae15ccc51e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6898\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 1070\n",
            "  Number of trainable parameters = 66955010\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1070' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1070/1070 05:46, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.277300</td>\n",
              "      <td>0.301811</td>\n",
              "      <td>0.894328</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.166900</td>\n",
              "      <td>0.268484</td>\n",
              "      <td>0.902687</td>\n",
              "      <td>0.204878</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.118644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.156600</td>\n",
              "      <td>0.225041</td>\n",
              "      <td>0.902687</td>\n",
              "      <td>0.507553</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.474576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.128600</td>\n",
              "      <td>0.273485</td>\n",
              "      <td>0.916418</td>\n",
              "      <td>0.448819</td>\n",
              "      <td>0.740260</td>\n",
              "      <td>0.322034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.064300</td>\n",
              "      <td>0.284360</td>\n",
              "      <td>0.899104</td>\n",
              "      <td>0.512968</td>\n",
              "      <td>0.523529</td>\n",
              "      <td>0.502825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.059500</td>\n",
              "      <td>0.377547</td>\n",
              "      <td>0.885970</td>\n",
              "      <td>0.501305</td>\n",
              "      <td>0.466019</td>\n",
              "      <td>0.542373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.426555</td>\n",
              "      <td>0.905075</td>\n",
              "      <td>0.516717</td>\n",
              "      <td>0.559211</td>\n",
              "      <td>0.480226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.466945</td>\n",
              "      <td>0.899701</td>\n",
              "      <td>0.505882</td>\n",
              "      <td>0.527607</td>\n",
              "      <td>0.485876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.008700</td>\n",
              "      <td>0.482433</td>\n",
              "      <td>0.909254</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.451977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.486653</td>\n",
              "      <td>0.911045</td>\n",
              "      <td>0.517799</td>\n",
              "      <td>0.606061</td>\n",
              "      <td>0.451977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-107\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-107/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-107/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-214\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-214/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-214/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-321\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-321/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-321/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-428\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-428/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-428/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-535\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-535/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-535/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-642\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-642/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-642/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-749\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-749/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-749/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-856\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-856/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-856/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-963\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-963/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-963/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1070\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1070/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1070/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-1070 (score: 0.5177993527508091).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1070, training_loss=0.12616111923914367, metrics={'train_runtime': 347.1995, 'train_samples_per_second': 198.675, 'train_steps_per_second': 3.082, 'total_flos': 9130977789358080.0, 'train_loss': 0.12616111923914367, 'epoch': 9.99})"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "405b4eff",
      "metadata": {
        "id": "405b4eff"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cab2a3dc",
      "metadata": {
        "id": "cab2a3dc"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "6ac97c8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ac97c8e",
        "outputId": "d34e0433-a7c4-4594-f70a-3cb21bd2d57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/distilbert\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/distilbert/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/distilbert/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer.save_model(f'{results_folder}/distilbert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f2Aqt-5l7X",
      "metadata": {
        "id": "27f2Aqt-5l7X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "_PZCZgNl5nGp",
      "metadata": {
        "id": "_PZCZgNl5nGp"
      },
      "source": [
        "### Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "QcYDjwOI5l96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcYDjwOI5l96",
        "outputId": "e07d4ee5-4b28-439a-daed-c32c445d71e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/NLP/results/distilbert/config.json\n",
            "You are using a model of type distilbert to instantiate a model of type longformer. This is not supported for all configurations of models and can yield errors.\n",
            "Model config LongformerConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"attention_window\": 512,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"longformer\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"onnx_export\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"sep_token_id\": 2,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/NLP/results/distilbert/pytorch_model.bin\n",
            "Some weights of the model checkpoint at /content/drive/MyDrive/NLP/results/distilbert were not used when initializing LongformerForSequenceClassification: ['distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'pre_classifier.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'pre_classifier.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'classifier.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'classifier.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight']\n",
            "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/results/distilbert and are newly initialized: ['encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.9.intermediate.dense.weight', 'classifier.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.8.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key_global.bias', 'classifier.out_proj.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.key_global.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value_global.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key_global.bias', 'encoder.layer.9.attention.self.value_global.bias', 'encoder.layer.7.attention.self.key_global.weight', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.attention.self.value_global.weight', 'classifier.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'classifier.out_proj.weight', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.key.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trained_model = LongformerForSequenceClassification.from_pretrained(\n",
        "    f'{results_folder}/distilbert',\n",
        "    num_labels=2, \n",
        "    id2label=id2label, \n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "mofGwDpj69jO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "mofGwDpj69jO",
        "outputId": "e867718d-e8c4-49d5-d368-44dbaa450d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.4866526424884796,\n",
              " 'eval_accuracy': 0.9110447761194029,\n",
              " 'eval_f1': 0.5177993527508091,\n",
              " 'eval_precision': 0.6060606060606061,\n",
              " 'eval_recall': 0.4519774011299435,\n",
              " 'eval_runtime': 1.9692,\n",
              " 'eval_samples_per_second': 850.619,\n",
              " 'eval_steps_per_second': 53.322,\n",
              " 'epoch': 9.99}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1360ef1",
      "metadata": {
        "id": "e1360ef1"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "bb767e66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "bb767e66",
        "outputId": "dae2f7dc-a635-4e95-b9df-f262605a2c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "dev_set_preds, labels, metrics = trainer.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVM65wl8gK_3",
        "outputId": "f55fccd8-7b41-47fe-c94c-3e0987ef5abb"
      },
      "id": "hVM65wl8gK_3",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss': 0.4379754960536957,\n",
              " 'dev_accuracy': 0.9168657429526995,\n",
              " 'dev_f1': 0.5139664804469273,\n",
              " 'dev_precision': 0.5786163522012578,\n",
              " 'dev_recall': 0.4623115577889447,\n",
              " 'dev_runtime': 2.658,\n",
              " 'dev_samples_per_second': 787.421,\n",
              " 'dev_steps_per_second': 49.284}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1957145",
      "metadata": {
        "id": "d1957145"
      },
      "outputs": [],
      "source": [
        "dev_set_preds = np.argmax(dev_set_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297919af",
      "metadata": {
        "id": "297919af"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb63528ab0e246d2bce1d3cd4ed4ecf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67173bddc1504a0a8e78bd46216c580f",
              "IPY_MODEL_2e12f20aee974492b1548dd565fbf4b0",
              "IPY_MODEL_222769494c89412b9f78f5b6257745f4"
            ],
            "layout": "IPY_MODEL_18b2eea4ed0a4fbb9107647006dee309"
          }
        },
        "67173bddc1504a0a8e78bd46216c580f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a01f22876e467bbc126391c2274249",
            "placeholder": "​",
            "style": "IPY_MODEL_0b3e415e145943208600ba3a2054a2d2",
            "value": "Map: 100%"
          }
        },
        "2e12f20aee974492b1548dd565fbf4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d7f9e3d5d94426bfaef5591bcbf196",
            "max": 6898,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_630281d7488441ad93a0f322b005afaf",
            "value": 6898
          }
        },
        "222769494c89412b9f78f5b6257745f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6731d0dcdb4edf8d8d80ee0408efdd",
            "placeholder": "​",
            "style": "IPY_MODEL_e46fc16aea294684af0bae4970939cc9",
            "value": " 6898/6898 [00:01&lt;00:00, 4514.83 examples/s]"
          }
        },
        "18b2eea4ed0a4fbb9107647006dee309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c8a01f22876e467bbc126391c2274249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3e415e145943208600ba3a2054a2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d7f9e3d5d94426bfaef5591bcbf196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630281d7488441ad93a0f322b005afaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e6731d0dcdb4edf8d8d80ee0408efdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46fc16aea294684af0bae4970939cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba9d3bb5705843f9a7a48836f6b89c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea4ac2e9666346d59b5ee046bec790db",
              "IPY_MODEL_11a92bcc0b384bf29848e767eb3090b9",
              "IPY_MODEL_65e4e508be1d47d69bcea3509444f014"
            ],
            "layout": "IPY_MODEL_b39d687f49f74ab495e87373847d4ad5"
          }
        },
        "ea4ac2e9666346d59b5ee046bec790db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6da27b242aa4539a95696ce4095cda6",
            "placeholder": "​",
            "style": "IPY_MODEL_696a0698dea5417789253eafe46443a1",
            "value": "Map: 100%"
          }
        },
        "11a92bcc0b384bf29848e767eb3090b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e8abd697a24cc5aff27bc7319ccffe",
            "max": 1675,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f524ec9eaa84d6fbae470a6a356c617",
            "value": 1675
          }
        },
        "65e4e508be1d47d69bcea3509444f014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d621d726274d5a8bd25087c51537c8",
            "placeholder": "​",
            "style": "IPY_MODEL_450c1708cb434cf989a613d3ca53c761",
            "value": " 1675/1675 [00:00&lt;00:00, 5543.45 examples/s]"
          }
        },
        "b39d687f49f74ab495e87373847d4ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e6da27b242aa4539a95696ce4095cda6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696a0698dea5417789253eafe46443a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9e8abd697a24cc5aff27bc7319ccffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f524ec9eaa84d6fbae470a6a356c617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73d621d726274d5a8bd25087c51537c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "450c1708cb434cf989a613d3ca53c761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "515d1f1bf8804ee4b4b5746c8b589ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6e54fc57f5a46599882cd951740a3c7",
              "IPY_MODEL_0485d83c10de4407b26e7e65b7f7c36b",
              "IPY_MODEL_10710b9b8df6407eb36cd495168270a6"
            ],
            "layout": "IPY_MODEL_30438ec707384602968b7d0430a30429"
          }
        },
        "f6e54fc57f5a46599882cd951740a3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe96bf03cac48fdb2857f0e12f45b30",
            "placeholder": "​",
            "style": "IPY_MODEL_61e8d6754498413a8b98436837ef294a",
            "value": "Map: 100%"
          }
        },
        "0485d83c10de4407b26e7e65b7f7c36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9643a881f60f4fb9bcc59955b29ffefe",
            "max": 2093,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24e08ba53b67435883de524a3986ac43",
            "value": 2093
          }
        },
        "10710b9b8df6407eb36cd495168270a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e9536eb7e142ab9951d57dd04784d2",
            "placeholder": "​",
            "style": "IPY_MODEL_c64ac4f5e1e64ef19b6b1aa4f705b9ba",
            "value": " 2093/2093 [00:00&lt;00:00, 5149.29 examples/s]"
          }
        },
        "30438ec707384602968b7d0430a30429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fbe96bf03cac48fdb2857f0e12f45b30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e8d6754498413a8b98436837ef294a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9643a881f60f4fb9bcc59955b29ffefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e08ba53b67435883de524a3986ac43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09e9536eb7e142ab9951d57dd04784d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c64ac4f5e1e64ef19b6b1aa4f705b9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}