{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgjx1VplEuJ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EuA-DSNlEuK",
        "outputId": "fe0bb396-fc68-484f-e92b-91ee51623f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.1)\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (22.2.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (20.20.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.0.4)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.51.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (3.19.6)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (2.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (0.8.10)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[tune]) (3.0.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (0.19.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[tune]) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets \"ray[tune]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iovM37elEuL",
        "outputId": "d9b013cf-041d-48a8-b3c5-3c203ee0a8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "WORKING_ENV = 'COLAB' #Â Can be LABS, COLAB or PAPERSPACE\n",
        "\n",
        "assert WORKING_ENV in ['COLAB', 'PAPERSPACE']\n",
        "\n",
        "if WORKING_ENV == 'COLAB':\n",
        "    from google.colab import drive\n",
        "    %load_ext google.colab.data_table\n",
        "    content_path = '/content/drive/MyDrive/'\n",
        "    drive.mount('/content/drive/', force_remount=True) # Outputs will be saved in your google drive\n",
        "\n",
        "else: # Using Paperspace\n",
        "    # Paperspace does not properly render animated progress bars\n",
        "    # Strongly recommend using the JupyterLab UI instead of theirs\n",
        "    !pip install ipywidgets \n",
        "    content_path = '/notebooks'\n",
        "\n",
        "content_path = Path(content_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1V8qI6aYlEuS"
      },
      "outputs": [],
      "source": [
        "data_folder = f\"{content_path}/NLP/data\"\n",
        "results_folder = f\"{content_path}/NLP/results\"\n",
        "logging_folder = f\"{content_path}/NLP/logs\"\n",
        "hp_search_folder = f\"{content_path}/NLP/hp_search\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "EmwDpaN3lEuS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding, AutoModelForSequenceClassification, DebertaTokenizer\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import datasets\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VzYxuz73lEuS"
      },
      "outputs": [],
      "source": [
        "# from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "# from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "# from ray.tune import CLIReporter\n",
        "# from ray import tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NcAfsnwQlEuS",
        "outputId": "f318ab76-b211-47b0-c2b4-52e9ae610e4f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAkYaA4olEuT"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "m0LrrBbRlEuT"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pd.read_csv(f\"{data_folder}/pcl_df_train_train_preprocessed.csv\")\n",
        "pcl_df_train_train_aug = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug.csv\")\n",
        "pcl_df_train_train_gpt = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug_chatgpt.csv\")\n",
        "\n",
        "\n",
        "pcl_df_train_dev = pd.read_csv(f\"{data_folder}/pcl_df_train_dev_preprocessed.csv\")\n",
        "pcl_df_dev = pd.read_csv(f\"{data_folder}/pcl_df_dev_preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oakr1Wwvl0bk",
        "outputId": "8af7c32d-179b-4cbb-eb08-c6a422ac2cdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6700, 8)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaE315Jel4pA",
        "outputId": "9a9f2724-2c77-4646-ad48-7029420f3bd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    6075\n",
              "1     625\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train[\"class\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTNkBp_cHLHI",
        "outputId": "6ac6812c-4e7e-412b-e38e-1c26827208fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12150, 7)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_aug.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEqUoiOdHK7x",
        "outputId": "ee8988f4-8d6e-40ae-9d92-708f78c08d10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    6075\n",
              "1    6075\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_aug[\"class\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38O4WjMhE8N7",
        "outputId": "9d2adfe7-2eb9-4f13-8e20-44ad407bcc87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13983, 7)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_gpt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsVbSP7sE9Uv",
        "outputId": "5b5b4edd-b114-48bb-ad7b-50f5ef2d5c30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    7908\n",
              "0    6075\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_gpt[\"class\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUaIm5YKlEuT",
        "outputId": "4e503841-23aa-4cc4-ef2a-20f19e3678d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['par_id', 'art_id', 'keyword', 'country_code', 'text', 'label', 'class',\n",
              "       'preprocessed_text'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "L21SW-C5lEuT"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train[['text', 'class']]\n",
        "pcl_df_train_train_aug = pcl_df_train_train_aug[['text', 'class']]\n",
        "pcl_df_train_train_gpt = pcl_df_train_train_gpt[['text', 'class']]\n",
        "\n",
        "\n",
        "pcl_df_train_dev = pcl_df_train_dev[['text', 'class']]\n",
        "pcl_df_dev = pcl_df_dev[['text', 'class']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "k-4cgtYulEuT"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = datasets.Dataset.from_pandas(pcl_df_train_train)\n",
        "pcl_df_train_train_aug = datasets.Dataset.from_pandas(pcl_df_train_train_aug)\n",
        "pcl_df_train_train_gpt = datasets.Dataset.from_pandas(pcl_df_train_train_gpt)\n",
        "\n",
        "pcl_df_train_dev = datasets.Dataset.from_pandas(pcl_df_train_dev)\n",
        "pcl_df_dev = datasets.Dataset.from_pandas(pcl_df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv58bdWRlEuT",
        "outputId": "00bf8ba5-4555-4d03-d66e-d68327669fab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pcl_df_train_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "81HCcrLClEuT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv7_FOd_lEuT"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "__IfKbqUlEuU"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckWZzzyAlEuU",
        "outputId": "5505ba10-0198-495e-a5bc-5866b056703e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/merges.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def model_init_clf():\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"microsoft/deberta-base\", \n",
        "        num_labels=2, \n",
        "        id2label=id2label, \n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "    model.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Linear(768, 1024),\n",
        "        torch.nn.BatchNorm1d(1024),\n",
        "        torch.nn.Dropout(0.2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(1024, 256),\n",
        "        torch.nn.BatchNorm1d(256),\n",
        "        torch.nn.Dropout(0.2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(256, 64),\n",
        "        torch.nn.BatchNorm1d(64),\n",
        "        torch.nn.Dropout(0.2),\n",
        "        torch.nn.ReLU(),  \n",
        "        torch.nn.Linear(64, 2),\n",
        "        torch.nn.Softmax(dim=-1)\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def model_init():\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"microsoft/deberta-base\", \n",
        "        num_labels=2, \n",
        "        id2label=id2label, \n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "QW5zPfv_lEuU"
      },
      "outputs": [],
      "source": [
        "def tokenization(batched_text):\n",
        "    return tokenizer(\n",
        "        batched_text['text'], \n",
        "        padding = 'max_length', \n",
        "        truncation=True, \n",
        "        max_length = 512\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "L5zAO8FYlEuU"
      },
      "outputs": [],
      "source": [
        "# define accuracy metrics\n",
        "def compute_metrics(pred):\n",
        "    preds, labels = pred\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='binary'\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hBT-w6wXlEuU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQP81lQNlEuU"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "20adb723d4a34486ad77f5dfcb483356",
            "ebbf9bdec9f04e5a8a9b8def27873b8d",
            "ccb5e099a6084564b82dc2ccaf60e9e5",
            "07736adb56854abd811bfd5039417cc8",
            "94da0e5dc8a44c11b1441cc34fdff050",
            "f6c6cc6a6e644b64a6ce60259a65fa4a",
            "1f627ddb906347bc879a076db81f3e2e",
            "52f6b770594c40fa81f2e3d58995dc49",
            "a717924b37a1445eb5cb2bef6d9aeef4",
            "889bc5d5a7fb4c81aa76cd8361f1589e",
            "e28f1c3ac27f42cbb8b66561388d4a2f",
            "9cb89b7b0e004825a445f3f5b15378dd",
            "56540818c12241efae7581bd560c147a",
            "c49ab61037b9458d9921ce0de44bb6ad",
            "570e80502482476c8a000c5163322c75",
            "590dd7265b6643908ab4cc240520f777",
            "54f3e9ef49a942689dab707cf6c21196",
            "c04eba6b62964181a06f45e159220910",
            "477239166cc64f57a8d22801a6c76180",
            "341c9177372941c8854752f45f939869",
            "f76138fefa81452c87637a39c2ee55fe",
            "504ecbfd6d764961a14a5bc508a866a4",
            "3056f69e94684375a26d47b107d99b9c",
            "f11f12d4125b4acca429b0a9dfb01cc1",
            "0611bd1e14e346ff81b46d147fe7f647",
            "1504258092694b329a7149624d4208e8",
            "a4ce9fa6ab5a4146bb52b5e79369f132",
            "a29d09ca15154d93a8a52d3baf8ba76a",
            "d8d1182c35754f7d8f89e91c0d38e851",
            "ef12810330a9407a9a9ec4a78d2b1b20",
            "9125cb00c7f9479a99ad53466b6b2905",
            "98c530eee473475a97d865ba84732283",
            "e29ef384b04b4580b0565a6f5940bedf",
            "bcb6d3237a0941f2959d3edaab5e3c8f",
            "e5f2b8d3b51042629afdc23fede0fe4c",
            "e7bbcc0054f9476da517d00dffab3f1a",
            "d5502834665142fb8158e5b1bc538421",
            "abd3547487964f58b25f7e5d0da91abb",
            "3ff00871c6674da48d72218e6cb2780c",
            "9f4d555135ec43f9a86f58321872cc4c",
            "bd0335fcc65f4c8c81d4879efe658569",
            "c9b5f7a4c1b4441695b1666ceb81b9e9",
            "dc5edf821f104a0cb3a6b0bd223a6dc0",
            "fcd0715f32ca4a81a0e72608dda984a1",
            "1ae4c48b2f4244c3b9c8f4ab8cd7ba5d",
            "32570f3b2d7941ca8d8a79bf335e397f",
            "54aa0bdc516142968c046d4b643262c1",
            "a26a34fcb5854a9c9aa0901cf07ac543",
            "03aa1e4b5b224a6892fa797813b46df8",
            "1248a9d2238744d0962e7824b6cac6b8",
            "5a8b57422a0d478994af5f8197790e01",
            "bf3c8bf5f5024d9eab3d93cef46cb3f8",
            "22b10961c3f549cc9220b50061fd9440",
            "38ba35c409a44894a713af41d35d6e48",
            "eee7598001474e7ca6dbd707d688fc75"
          ]
        },
        "id": "y8oKSLDllEuU",
        "outputId": "b4ab5825-a975-4f35-fa42-7067fa182027"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-16:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 247, in run\n",
            "    self._record_writer.flush()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/summary/writer/record_writer.py\", line 43, in flush\n",
            "    self._writer.flush()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 221, in flush\n",
            "    self._writable_file.flush()\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/MyDrive/NLP/logs/events.out.tfevents.1678118948.bab67a06e9e0.46919.2; Transport endpoint is not connected\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20adb723d4a34486ad77f5dfcb483356",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6700 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cb89b7b0e004825a445f3f5b15378dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3056f69e94684375a26d47b107d99b9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/13983 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcb6d3237a0941f2959d3edaab5e3c8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1675 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ae4c48b2f4244c3b9c8f4ab8cd7ba5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train)\n",
        ")\n",
        "\n",
        "pcl_df_train_train_aug = pcl_df_train_train_aug.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train_aug)\n",
        ")\n",
        "\n",
        "pcl_df_train_train_gpt = pcl_df_train_train_gpt.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train_gpt)\n",
        ")\n",
        "\n",
        "\n",
        "pcl_df_train_dev = pcl_df_train_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_dev)\n",
        ")\n",
        "\n",
        "pcl_df_dev = pcl_df_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_dev)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "B6hmkcf9lEuU"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "\n",
        "pcl_df_train_train_aug.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "\n",
        "pcl_df_train_train_gpt.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "pcl_df_train_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "pcl_df_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "P5akw4NdlEuV"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.rename_column(\"class\", \"label\")\n",
        "pcl_df_train_train_aug= pcl_df_train_train_aug.rename_column(\"class\", \"label\")\n",
        "pcl_df_train_train_gpt = pcl_df_train_train_gpt.rename_column(\"class\", \"label\")\n",
        "\n",
        "\n",
        "pcl_df_train_dev = pcl_df_train_dev.rename_column(\"class\", \"label\")\n",
        "pcl_df_dev = pcl_df_dev.rename_column(\"class\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "6gsGAU-MlEuV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBImiS2WlEuV"
      },
      "source": [
        "### Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iX2f3EwnlEuV"
      },
      "outputs": [],
      "source": [
        "learning_rate_vals = [1e-5, 2e-5]\n",
        "weight_decay_vals = [0.1, 0.01]\n",
        "per_device_train_batch_size_vals = [16, 32]\n",
        "warmup_steps_vals = [0, 200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mlV-9K51evT",
        "outputId": "7aafee1a-abc8-474b-cd3f-2b5d0ca590c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2e-05 0.1 16 0\n",
            "2e-05 0.1 16 200\n",
            "2e-05 0.1 32 0\n",
            "2e-05 0.1 32 200\n",
            "2e-05 0.01 16 0\n",
            "2e-05 0.01 16 200\n",
            "2e-05 0.01 32 0\n",
            "2e-05 0.01 32 200\n"
          ]
        }
      ],
      "source": [
        "for learning_rate, weight_decay, per_device_train_batch_size, warmup_steps in list(\n",
        "    itertools.product(\n",
        "    learning_rate_vals, weight_decay_vals, \n",
        "    per_device_train_batch_size_vals, warmup_steps_vals)\n",
        "    ):\n",
        "  \n",
        "  print(learning_rate, weight_decay, per_device_train_batch_size, warmup_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J0sdzZKxlEuV",
        "outputId": "9cddcae4-5d58-4065-863a-60fbf78eea2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6700\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 520\n",
            "  Number of trainable parameters = 140261442\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 17/520 01:07 < 37:57, 0.22 it/s, Epoch 0.31/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [01:23<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0598d3ba344f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2569\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2571\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2572\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2573\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1235\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m                     \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "experiment_lr = []\n",
        "experiment_wd = []\n",
        "experiment_train_batch_size = []\n",
        "experiment_warmup = []\n",
        "\n",
        "experiment_acc = []\n",
        "experiment_precision = []\n",
        "experiment_recall = []\n",
        "experiment_f1 = []\n",
        "\n",
        "for learning_rate, weight_decay, per_device_train_batch_size, warmup_steps in tqdm(\n",
        "    list(\n",
        "    itertools.product(\n",
        "    learning_rate_vals, weight_decay_vals, \n",
        "    per_device_train_batch_size_vals, warmup_steps_vals)\n",
        "    )):\n",
        "    \n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=hp_search_folder, \n",
        "        learning_rate=learning_rate,  # config\n",
        "        warmup_steps=warmup_steps, #config\n",
        "        weight_decay=weight_decay,  # config\n",
        "        per_device_train_batch_size=per_device_train_batch_size,  # config\n",
        "        num_train_epochs=10,\n",
        "        per_device_eval_batch_size=16, \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        gradient_accumulation_steps=8,\n",
        "        logging_steps=100,\n",
        "        logging_dir=logging_folder,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        args=training_args,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    metrics = trainer.evaluate()\n",
        "\n",
        "    experiment_lr.append(learning_rate)\n",
        "    experiment_wd.append(weight_decay)\n",
        "    experiment_train_batch_size.append(per_device_train_batch_size)\n",
        "    experiment_warmup.append(warmup_steps)\n",
        "    experiment_acc.append(metrics['eval_accuracy'])\n",
        "    experiment_precision.append(metrics['eval_precision'])\n",
        "    experiment_recall.append(metrics['eval_recall'])\n",
        "    experiment_f1.append(metrics['eval_f1'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CVxis3jlEuV"
      },
      "outputs": [],
      "source": [
        "grid_search_results = pd.DataFrame({\n",
        "    'learning_rate': experiment_lr,\n",
        "    'weight_decay': experiment_wd,\n",
        "    'per_device_train_batch_size': experiment_train_batch_size,\n",
        "    'warmup_steps': experiment_warmup,\n",
        "    'accuracy': experiment_acc,\n",
        "    'precision': experiment_precision,\n",
        "    'recall': experiment_recall,\n",
        "    'f1': experiment_f1\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q9P3zQKlEuV"
      },
      "outputs": [],
      "source": [
        "# get the best hyperparameters with highest f1 score\n",
        "grid_search_results = grid_search_results.sort_values(by='f1', ascending=False)\n",
        "grid_search_results.to_csv(f\"{results_folder}_grid_search_results.csv\", index=False)\n",
        "\n",
        "# get the first row of the dataframe\n",
        "best_hyperparameters = grid_search_results.iloc[0]\n",
        "\n",
        "# get the best hyperparameters\n",
        "best_learning_rate = best_hyperparameters['learning_rate']\n",
        "best_weight_decay = best_hyperparameters['weight_decay']\n",
        "best_per_device_train_batch_size = int(best_hyperparameters['per_device_train_batch_size'])\n",
        "best_warmup_steps = int(best_hyperparameters['warmup_steps'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vi89ZY-lEuW"
      },
      "outputs": [],
      "source": [
        "best_hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vySZpNgPkBG0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDAExOUQkCzU"
      },
      "source": [
        "### Train with best hyperparameters on the original train data (without modified classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "qm-CwCECkCzU"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu86Uy-xkCzU",
        "outputId": "ce786f90-b7b7-4e62-c30b-461adb12910b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_og = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-og'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq0dk_WhkCzU",
        "outputId": "52a75fe6-1148-45e3-82f7-cf1f95c7a38b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_og = Trainer(\n",
        "        args=training_args_og,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AcSlDQf0kCzU",
        "outputId": "232c9ed6-5c18-4ec2-b96b-845f6d035580"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 6700\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 260\n",
            "  Number of trainable parameters = 139193858\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 09:29, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.226401</td>\n",
              "      <td>0.912239</td>\n",
              "      <td>0.316279</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.201183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.282100</td>\n",
              "      <td>0.197442</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.507353</td>\n",
              "      <td>0.669903</td>\n",
              "      <td>0.408284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.282100</td>\n",
              "      <td>0.212624</td>\n",
              "      <td>0.921194</td>\n",
              "      <td>0.525180</td>\n",
              "      <td>0.669725</td>\n",
              "      <td>0.431953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.148400</td>\n",
              "      <td>0.218819</td>\n",
              "      <td>0.922388</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.693069</td>\n",
              "      <td>0.414201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.148400</td>\n",
              "      <td>0.225651</td>\n",
              "      <td>0.920597</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>0.652542</td>\n",
              "      <td>0.455621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-52\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-52/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-52/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-104\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-104/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-104/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-156\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-156/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-156/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-208\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-208/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-208/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-260\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-260/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-260/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-260 (score: 0.5365853658536586).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=260, training_loss=0.18767846180842473, metrics={'train_runtime': 571.2245, 'train_samples_per_second': 58.646, 'train_steps_per_second': 0.455, 'total_flos': 1.0257529279905792e+16, 'train_loss': 0.18767846180842473, 'epoch': 4.99})"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_og.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-NelUsR8kCzU",
        "outputId": "4bb9e646-6788-4859-cbd8-60f099934582"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2256513237953186,\n",
              " 'eval_accuracy': 0.9205970149253732,\n",
              " 'eval_f1': 0.5365853658536586,\n",
              " 'eval_precision': 0.652542372881356,\n",
              " 'eval_recall': 0.4556213017751479,\n",
              " 'eval_runtime': 8.3648,\n",
              " 'eval_samples_per_second': 200.245,\n",
              " 'eval_steps_per_second': 12.553,\n",
              " 'epoch': 4.99}"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_og.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3YhWoCakCzU"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "nBoMx6E4kCzU",
        "outputId": "c6541a8f-3ae1-4ca8-e758-aae2e13700df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_og, dev_set_labels_og, dev_set_metrics_og = trainer_og.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSKolWelkCzU",
        "outputId": "776cfba8-e431-498c-a5bf-6e19e079037a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.2107057124376297,\n",
              " 'dev_accuracy': 0.9235912129894938,\n",
              " 'dev_f1': 0.550561797752809,\n",
              " 'dev_precision': 0.6242038216560509,\n",
              " 'dev_recall': 0.49246231155778897,\n",
              " 'dev_runtime': 10.543,\n",
              " 'dev_samples_per_second': 198.615,\n",
              " 'dev_steps_per_second': 12.425}"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_og"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "sAHcEOejkCzU"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_og = np.argmax(dev_set_preds_og)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "faDsZhdCkCzU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t38j1kUytZQy"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTtVwSORtZQ6",
        "outputId": "456e2706-7b3d-4307-c584-a5413219252a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_og\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_og/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_og/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_og/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_og/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_og.save_model(f'{results_folder}/deberta_og')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIKajlIwta_N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb6o_VWPlEuW"
      },
      "source": [
        "### Train with best hyperparameters on the original train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "DcCVTnH8lEuW"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnKuPaIRlEuW",
        "outputId": "cad8b641-f227-4a54-fadf-6b95372e1da1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1Hty6hGlEuW",
        "outputId": "192e6930-7047-4fec-c5fa-fabea600b19f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "        args=training_args,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9xY2h-JrlEuW",
        "outputId": "7d13b9cd-26fa-42be-8347-a96643c24ac3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6700\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 260\n",
            "  Number of trainable parameters = 140261442\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 09:28, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.625831</td>\n",
              "      <td>0.899104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.656800</td>\n",
              "      <td>0.624853</td>\n",
              "      <td>0.899104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.656800</td>\n",
              "      <td>0.598154</td>\n",
              "      <td>0.899701</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.011834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.637400</td>\n",
              "      <td>0.600669</td>\n",
              "      <td>0.865672</td>\n",
              "      <td>0.380165</td>\n",
              "      <td>0.355670</td>\n",
              "      <td>0.408284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.637400</td>\n",
              "      <td>0.612650</td>\n",
              "      <td>0.833433</td>\n",
              "      <td>0.449704</td>\n",
              "      <td>0.337278</td>\n",
              "      <td>0.674556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-52\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-52/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-52/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-104\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-104/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-104/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-156\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-156/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-156/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-208\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-208/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-208/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-260\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-260/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-260/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-260 (score: 0.44970414201183434).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=260, training_loss=0.6420766537006085, metrics={'train_runtime': 570.8137, 'train_samples_per_second': 58.688, 'train_steps_per_second': 0.455, 'total_flos': 1.036725218131968e+16, 'train_loss': 0.6420766537006085, 'epoch': 4.99})"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_msT_dXjlEuW",
        "outputId": "a63c8fde-e2f2-46a7-e1b8-4c2b5ec9ca13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6126503348350525,\n",
              " 'eval_accuracy': 0.8334328358208956,\n",
              " 'eval_f1': 0.44970414201183434,\n",
              " 'eval_precision': 0.33727810650887574,\n",
              " 'eval_recall': 0.6745562130177515,\n",
              " 'eval_runtime': 8.3784,\n",
              " 'eval_samples_per_second': 199.92,\n",
              " 'eval_steps_per_second': 12.532,\n",
              " 'epoch': 4.99}"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyg8tzSxlEuX"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "c2GH4weSlEuX",
        "outputId": "7451205d-3ea4-44b5-a002-d7f1c1bce725"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds, dev_set_labels, dev_set_metrics = trainer.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOfLLcA1lEuX",
        "outputId": "479a10df-9557-478d-c67e-63e3c244d8df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.6138441562652588,\n",
              " 'dev_accuracy': 0.8247373447946514,\n",
              " 'dev_f1': 0.41279999999999994,\n",
              " 'dev_precision': 0.3028169014084507,\n",
              " 'dev_recall': 0.6482412060301508,\n",
              " 'dev_runtime': 10.5319,\n",
              " 'dev_samples_per_second': 198.824,\n",
              " 'dev_steps_per_second': 12.438}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "QUn9CsNllEuX"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels = np.argmax(dev_set_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "brjXX3f3Dl9L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYEcYsGktvw3"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHKQAWMetvw3",
        "outputId": "368d980a-4af2-4285-b16a-e0a1ff99adfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer.save_model(f'{results_folder}/deberta')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "_mYeHlqoIbtQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPMGsxoKIc2L"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data (without chatgpt data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "vGFOCEZ9Ic2L"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3cAjJmyIc2L",
        "outputId": "f04eba72-7b40-4830-c9c7-ba0c99030901"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_aug = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-aug'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmTnLlaGIc2L",
        "outputId": "90c1e0a0-1512-43a8-ba1d-cb574dd6e232"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_aug = Trainer(\n",
        "        args=training_args_aug,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_aug,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EWCLlywyIc2M",
        "outputId": "6c8b849c-f7b4-4483-8c76-adb32d9529ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12150\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 475\n",
            "  Number of trainable parameters = 140261442\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 16:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.455971</td>\n",
              "      <td>0.887761</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.193548</td>\n",
              "      <td>0.035503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.520700</td>\n",
              "      <td>0.448133</td>\n",
              "      <td>0.902090</td>\n",
              "      <td>0.203883</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.124260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.447700</td>\n",
              "      <td>0.435982</td>\n",
              "      <td>0.917612</td>\n",
              "      <td>0.546053</td>\n",
              "      <td>0.614815</td>\n",
              "      <td>0.491124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.423400</td>\n",
              "      <td>0.418351</td>\n",
              "      <td>0.921791</td>\n",
              "      <td>0.501901</td>\n",
              "      <td>0.702128</td>\n",
              "      <td>0.390533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.407600</td>\n",
              "      <td>0.416931</td>\n",
              "      <td>0.917612</td>\n",
              "      <td>0.543046</td>\n",
              "      <td>0.616541</td>\n",
              "      <td>0.485207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-95\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-95/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-95/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-95/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-95/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-190\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-190/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-190/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-190/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-190/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-285\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-285/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-285/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-285/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-285/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-380\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-380/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-380/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-380/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-380/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-475\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-475/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-475/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-475/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-475/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-285 (score: 0.5460526315789473).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=475, training_loss=0.4418833883185136, metrics={'train_runtime': 965.0952, 'train_samples_per_second': 62.947, 'train_steps_per_second': 0.492, 'total_flos': 1.882504094976e+16, 'train_loss': 0.4418833883185136, 'epoch': 5.0})"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_aug.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "24ISWa3_Ic2M",
        "outputId": "02bfec64-4251-448e-9782-01615ef7d186"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.4359823167324066,\n",
              " 'eval_accuracy': 0.9176119402985075,\n",
              " 'eval_f1': 0.5460526315789473,\n",
              " 'eval_precision': 0.6148148148148148,\n",
              " 'eval_recall': 0.4911242603550296,\n",
              " 'eval_runtime': 8.3922,\n",
              " 'eval_samples_per_second': 199.591,\n",
              " 'eval_steps_per_second': 12.512,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_aug.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh8hESJzIc2M"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "zU3HV55WIc2M",
        "outputId": "d843a872-9193-4bda-d9f7-d510a6bffc32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_aug, dev_set_labels_aug, dev_set_metrics_aug = trainer_aug.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVk3Z0efIc2M",
        "outputId": "8e648453-ede2-4c33-dd31-ed76831595f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.4416044056415558,\n",
              " 'dev_accuracy': 0.9173829990448902,\n",
              " 'dev_f1': 0.5181058495821728,\n",
              " 'dev_precision': 0.58125,\n",
              " 'dev_recall': 0.46733668341708545,\n",
              " 'dev_runtime': 10.5645,\n",
              " 'dev_samples_per_second': 198.211,\n",
              " 'dev_steps_per_second': 12.4}"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "VjfGTx8GIc2M"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_aug = np.argmax(dev_set_preds_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYmTVjcnlEuX"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnf8Z3wglEuX",
        "outputId": "722ed9f6-39af-4720-d5d2-23f31849dd88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_aug\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_aug/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_aug/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_aug/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_aug/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_aug.save_model(f'{results_folder}/deberta_aug')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcGwwvh-Dleu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDeeJ6XnDo13"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data + chatgpt data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Xre1yKwdDo13"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKTNvT0ZDo14",
        "outputId": "fa594697-0585-4a52-ff9f-aaad80d2c5d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_gpt = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-gpt'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vwcSqXHDo14",
        "outputId": "4c87e529-8fe1-48df-9f5a-08697f83e3bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_gpt = Trainer(\n",
        "        args=training_args_gpt,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_gpt,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kDCzUeziDo14",
        "outputId": "9ac56d4b-e8af-4add-f65b-7a2653527b13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13983\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 545\n",
            "  Number of trainable parameters = 140261442\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='545' max='545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [545/545 18:30, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.443908</td>\n",
              "      <td>0.898507</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.421078</td>\n",
              "      <td>0.918806</td>\n",
              "      <td>0.358491</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.224852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.420600</td>\n",
              "      <td>0.410190</td>\n",
              "      <td>0.921194</td>\n",
              "      <td>0.426087</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.289941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.407000</td>\n",
              "      <td>0.405032</td>\n",
              "      <td>0.922388</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.394900</td>\n",
              "      <td>0.403793</td>\n",
              "      <td>0.920597</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>0.652542</td>\n",
              "      <td>0.455621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-109\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-109/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-109/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-109/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-109/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-218\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-218/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-218/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-218/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-218/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-327\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-327/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-327/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-327/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-327/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-436\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-436/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-436/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-436/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-436/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-545\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-545/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-545/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-545/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-545/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-436 (score: 0.5454545454545455).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=545, training_loss=0.43446609427075866, metrics={'train_runtime': 1112.7087, 'train_samples_per_second': 62.833, 'train_steps_per_second': 0.49, 'total_flos': 2.165545945239552e+16, 'train_loss': 0.43446609427075866, 'epoch': 5.0})"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_gpt.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "5rK5Vqx6Do14",
        "outputId": "010c9b10-d7bc-49eb-f23c-6207f7f1cd4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.40503227710723877,\n",
              " 'eval_accuracy': 0.9223880597014925,\n",
              " 'eval_f1': 0.5454545454545455,\n",
              " 'eval_precision': 0.6666666666666666,\n",
              " 'eval_recall': 0.46153846153846156,\n",
              " 'eval_runtime': 8.3583,\n",
              " 'eval_samples_per_second': 200.4,\n",
              " 'eval_steps_per_second': 12.562,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_gpt.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT6wPdn4Do14"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "uRYVzLntDo14",
        "outputId": "8e9255f0-2827-4c07-ae30-d82a31450acf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_gpt, dev_set_labels_gpt, dev_set_metrics_gpt = trainer_gpt.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp6D9GBUDo14",
        "outputId": "1f9b973a-3d7d-4b49-c451-28dd5decfb60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.4062204957008362,\n",
              " 'dev_accuracy': 0.9259789875835721,\n",
              " 'dev_f1': 0.5373134328358209,\n",
              " 'dev_precision': 0.6617647058823529,\n",
              " 'dev_recall': 0.45226130653266333,\n",
              " 'dev_runtime': 10.569,\n",
              " 'dev_samples_per_second': 198.127,\n",
              " 'dev_steps_per_second': 12.395}"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_gpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "r2yfM82CDo14"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_gpt = np.argmax(dev_set_preds_gpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LFVhN4WiY7d"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyavUSqeiY7e",
        "outputId": "095334c8-b937-4cb4-8dfb-81558e8982d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_gpt\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_gpt/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_gpt/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_gpt/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_gpt/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_gpt.save_model(f'{results_folder}/deberta_gpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzAJLwvpig-5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03aa1e4b5b224a6892fa797813b46df8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0611bd1e14e346ff81b46d147fe7f647": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef12810330a9407a9a9ec4a78d2b1b20",
            "max": 13983,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9125cb00c7f9479a99ad53466b6b2905",
            "value": 13983
          }
        },
        "07736adb56854abd811bfd5039417cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889bc5d5a7fb4c81aa76cd8361f1589e",
            "placeholder": "â",
            "style": "IPY_MODEL_e28f1c3ac27f42cbb8b66561388d4a2f",
            "value": " 6700/6700 [00:07&lt;00:00, 918.55 examples/s]"
          }
        },
        "1248a9d2238744d0962e7824b6cac6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1504258092694b329a7149624d4208e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c530eee473475a97d865ba84732283",
            "placeholder": "â",
            "style": "IPY_MODEL_e29ef384b04b4580b0565a6f5940bedf",
            "value": " 13983/13983 [00:12&lt;00:00, 1144.56 examples/s]"
          }
        },
        "1ae4c48b2f4244c3b9c8f4ab8cd7ba5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32570f3b2d7941ca8d8a79bf335e397f",
              "IPY_MODEL_54aa0bdc516142968c046d4b643262c1",
              "IPY_MODEL_a26a34fcb5854a9c9aa0901cf07ac543"
            ],
            "layout": "IPY_MODEL_03aa1e4b5b224a6892fa797813b46df8"
          }
        },
        "1f627ddb906347bc879a076db81f3e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20adb723d4a34486ad77f5dfcb483356": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebbf9bdec9f04e5a8a9b8def27873b8d",
              "IPY_MODEL_ccb5e099a6084564b82dc2ccaf60e9e5",
              "IPY_MODEL_07736adb56854abd811bfd5039417cc8"
            ],
            "layout": "IPY_MODEL_94da0e5dc8a44c11b1441cc34fdff050"
          }
        },
        "22b10961c3f549cc9220b50061fd9440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3056f69e94684375a26d47b107d99b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f11f12d4125b4acca429b0a9dfb01cc1",
              "IPY_MODEL_0611bd1e14e346ff81b46d147fe7f647",
              "IPY_MODEL_1504258092694b329a7149624d4208e8"
            ],
            "layout": "IPY_MODEL_a4ce9fa6ab5a4146bb52b5e79369f132"
          }
        },
        "32570f3b2d7941ca8d8a79bf335e397f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1248a9d2238744d0962e7824b6cac6b8",
            "placeholder": "â",
            "style": "IPY_MODEL_5a8b57422a0d478994af5f8197790e01",
            "value": "Map: 100%"
          }
        },
        "341c9177372941c8854752f45f939869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38ba35c409a44894a713af41d35d6e48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff00871c6674da48d72218e6cb2780c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477239166cc64f57a8d22801a6c76180": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504ecbfd6d764961a14a5bc508a866a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f6b770594c40fa81f2e3d58995dc49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54aa0bdc516142968c046d4b643262c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf3c8bf5f5024d9eab3d93cef46cb3f8",
            "max": 2094,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22b10961c3f549cc9220b50061fd9440",
            "value": 2094
          }
        },
        "54f3e9ef49a942689dab707cf6c21196": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56540818c12241efae7581bd560c147a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f3e9ef49a942689dab707cf6c21196",
            "placeholder": "â",
            "style": "IPY_MODEL_c04eba6b62964181a06f45e159220910",
            "value": "Map: 100%"
          }
        },
        "570e80502482476c8a000c5163322c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f76138fefa81452c87637a39c2ee55fe",
            "placeholder": "â",
            "style": "IPY_MODEL_504ecbfd6d764961a14a5bc508a866a4",
            "value": " 12150/12150 [00:10&lt;00:00, 1147.74 examples/s]"
          }
        },
        "590dd7265b6643908ab4cc240520f777": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5a8b57422a0d478994af5f8197790e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889bc5d5a7fb4c81aa76cd8361f1589e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9125cb00c7f9479a99ad53466b6b2905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94da0e5dc8a44c11b1441cc34fdff050": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "98c530eee473475a97d865ba84732283": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb89b7b0e004825a445f3f5b15378dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56540818c12241efae7581bd560c147a",
              "IPY_MODEL_c49ab61037b9458d9921ce0de44bb6ad",
              "IPY_MODEL_570e80502482476c8a000c5163322c75"
            ],
            "layout": "IPY_MODEL_590dd7265b6643908ab4cc240520f777"
          }
        },
        "9f4d555135ec43f9a86f58321872cc4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a26a34fcb5854a9c9aa0901cf07ac543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ba35c409a44894a713af41d35d6e48",
            "placeholder": "â",
            "style": "IPY_MODEL_eee7598001474e7ca6dbd707d688fc75",
            "value": " 2094/2094 [00:01&lt;00:00, 1092.10 examples/s]"
          }
        },
        "a29d09ca15154d93a8a52d3baf8ba76a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ce9fa6ab5a4146bb52b5e79369f132": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a717924b37a1445eb5cb2bef6d9aeef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abd3547487964f58b25f7e5d0da91abb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bcb6d3237a0941f2959d3edaab5e3c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5f2b8d3b51042629afdc23fede0fe4c",
              "IPY_MODEL_e7bbcc0054f9476da517d00dffab3f1a",
              "IPY_MODEL_d5502834665142fb8158e5b1bc538421"
            ],
            "layout": "IPY_MODEL_abd3547487964f58b25f7e5d0da91abb"
          }
        },
        "bd0335fcc65f4c8c81d4879efe658569": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf3c8bf5f5024d9eab3d93cef46cb3f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c04eba6b62964181a06f45e159220910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c49ab61037b9458d9921ce0de44bb6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_477239166cc64f57a8d22801a6c76180",
            "max": 12150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_341c9177372941c8854752f45f939869",
            "value": 12150
          }
        },
        "c9b5f7a4c1b4441695b1666ceb81b9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccb5e099a6084564b82dc2ccaf60e9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f6b770594c40fa81f2e3d58995dc49",
            "max": 6700,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a717924b37a1445eb5cb2bef6d9aeef4",
            "value": 6700
          }
        },
        "d5502834665142fb8158e5b1bc538421": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5edf821f104a0cb3a6b0bd223a6dc0",
            "placeholder": "â",
            "style": "IPY_MODEL_fcd0715f32ca4a81a0e72608dda984a1",
            "value": " 1675/1675 [00:01&lt;00:00, 1085.68 examples/s]"
          }
        },
        "d8d1182c35754f7d8f89e91c0d38e851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc5edf821f104a0cb3a6b0bd223a6dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28f1c3ac27f42cbb8b66561388d4a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e29ef384b04b4580b0565a6f5940bedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5f2b8d3b51042629afdc23fede0fe4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff00871c6674da48d72218e6cb2780c",
            "placeholder": "â",
            "style": "IPY_MODEL_9f4d555135ec43f9a86f58321872cc4c",
            "value": "Map: 100%"
          }
        },
        "e7bbcc0054f9476da517d00dffab3f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0335fcc65f4c8c81d4879efe658569",
            "max": 1675,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9b5f7a4c1b4441695b1666ceb81b9e9",
            "value": 1675
          }
        },
        "ebbf9bdec9f04e5a8a9b8def27873b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6c6cc6a6e644b64a6ce60259a65fa4a",
            "placeholder": "â",
            "style": "IPY_MODEL_1f627ddb906347bc879a076db81f3e2e",
            "value": "Map: 100%"
          }
        },
        "eee7598001474e7ca6dbd707d688fc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef12810330a9407a9a9ec4a78d2b1b20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f11f12d4125b4acca429b0a9dfb01cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29d09ca15154d93a8a52d3baf8ba76a",
            "placeholder": "â",
            "style": "IPY_MODEL_d8d1182c35754f7d8f89e91c0d38e851",
            "value": "Map: 100%"
          }
        },
        "f6c6cc6a6e644b64a6ce60259a65fa4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f76138fefa81452c87637a39c2ee55fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd0715f32ca4a81a0e72608dda984a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
