{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgjx1VplEuJ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EuA-DSNlEuK",
        "outputId": "a44ec2d1-ffbc-41c2-f673-d302cfbf7a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray[tune]\n",
            "  Downloading ray-2.3.0-cp38-cp38-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.20.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (8.1.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (22.2.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.0.4)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (3.19.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.51.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (0.8.10)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[tune]) (3.0.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (0.19.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[tune]) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: tokenizers, distlib, xxhash, virtualenv, tensorboardX, dill, responses, multiprocess, huggingface-hub, transformers, ray, datasets\n",
            "Successfully installed datasets-2.10.1 dill-0.3.6 distlib-0.3.6 huggingface-hub-0.12.1 multiprocess-0.70.14 ray-2.3.0 responses-0.18.0 tensorboardX-2.6 tokenizers-0.13.2 transformers-4.26.1 virtualenv-20.20.0 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets \"ray[tune]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iovM37elEuL",
        "outputId": "b5bdc99e-0182-4d87-c3e5-8956af035f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "WORKING_ENV = 'COLAB' # Can be LABS, COLAB or PAPERSPACE\n",
        "\n",
        "assert WORKING_ENV in ['COLAB', 'PAPERSPACE']\n",
        "\n",
        "if WORKING_ENV == 'COLAB':\n",
        "    from google.colab import drive\n",
        "    %load_ext google.colab.data_table\n",
        "    content_path = '/content/drive/MyDrive/'\n",
        "    drive.mount('/content/drive/', force_remount=True) # Outputs will be saved in your google drive\n",
        "\n",
        "else: # Using Paperspace\n",
        "    # Paperspace does not properly render animated progress bars\n",
        "    # Strongly recommend using the JupyterLab UI instead of theirs\n",
        "    !pip install ipywidgets \n",
        "    content_path = '/notebooks'\n",
        "\n",
        "content_path = Path(content_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1V8qI6aYlEuS"
      },
      "outputs": [],
      "source": [
        "data_folder = f\"{content_path}/NLP/data\"\n",
        "results_folder = f\"{content_path}/NLP/results\"\n",
        "logging_folder = f\"{content_path}/NLP/logs\"\n",
        "hp_search_folder = f\"{content_path}/NLP/hp_search\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EmwDpaN3lEuS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding, AutoModelForSequenceClassification, DebertaTokenizer\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import datasets\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NcAfsnwQlEuS",
        "outputId": "a1bf6e02-4a9f-4932-aa40-119e01f59412"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAkYaA4olEuT"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m0LrrBbRlEuT"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pd.read_csv(f\"{data_folder}/pcl_df_train_train_preprocessed.csv\")\n",
        "pcl_df_train_train_aug = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug.csv\")\n",
        "pcl_df_train_train_gpt = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug_chatgpt.csv\")\n",
        "\n",
        "pcl_df_train_dev = pd.read_csv(f\"{data_folder}/pcl_df_train_dev_preprocessed.csv\")\n",
        "pcl_df_dev = pd.read_csv(f\"{data_folder}/pcl_df_dev_preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oakr1Wwvl0bk",
        "outputId": "4ca56f85-4e7a-420b-af27-f26d334bd805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6700, 8)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaE315Jel4pA",
        "outputId": "340753d9-e5b6-4e27-f858-464f8e955743"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    6075\n",
              "1     625\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train[\"class\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTNkBp_cHLHI",
        "outputId": "98dbc061-63f2-4b65-f5f4-8c4a6b97c56b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12150, 7)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_aug.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEqUoiOdHK7x",
        "outputId": "d1554097-ff1d-4a84-ebb4-f15225d77887"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    6075\n",
              "1    6075\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_aug[\"class\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38O4WjMhE8N7",
        "outputId": "4c2391d6-c367-4099-efe2-2c80f1956236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13983, 7)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_gpt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsVbSP7sE9Uv",
        "outputId": "18b77f56-7e54-41a8-aa47-b63a0a3d6beb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    7908\n",
              "0    6075\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train_gpt[\"class\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUaIm5YKlEuT",
        "outputId": "e334a5c4-1727-44e0-b09c-9fe331592e7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['par_id', 'art_id', 'keyword', 'country_code', 'text', 'label', 'class',\n",
              "       'preprocessed_text'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_train_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L21SW-C5lEuT"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train[['text', 'class']]\n",
        "pcl_df_train_train_aug = pcl_df_train_train_aug[['text', 'class']]\n",
        "pcl_df_train_train_gpt = pcl_df_train_train_gpt[['text', 'class']]\n",
        "\n",
        "pcl_df_train_dev = pcl_df_train_dev[['text', 'class']]\n",
        "pcl_df_dev = pcl_df_dev[['text', 'class']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "k-4cgtYulEuT"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = datasets.Dataset.from_pandas(pcl_df_train_train)\n",
        "pcl_df_train_train_aug = datasets.Dataset.from_pandas(pcl_df_train_train_aug)\n",
        "pcl_df_train_train_gpt = datasets.Dataset.from_pandas(pcl_df_train_train_gpt)\n",
        "\n",
        "pcl_df_train_dev = datasets.Dataset.from_pandas(pcl_df_train_dev)\n",
        "pcl_df_dev = datasets.Dataset.from_pandas(pcl_df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv58bdWRlEuT",
        "outputId": "24f5323e-6c3d-4509-bf4b-cb024b533160"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pcl_df_train_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "81HCcrLClEuT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv7_FOd_lEuT"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "__IfKbqUlEuU"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "addc7c801af64ce285e9eba9f94fa1fe",
            "ec4f878fb27045e8b778d996ae7b721e",
            "1713341ac794472c92874501d1f57956",
            "2300bb7abd7d4c109a9efd2839ba51fe",
            "c75c08ff256d40039a8a0f7a0b9c560c",
            "cd45171b319b437294c8d181aaf71489",
            "9aa2dcaa4d8a47b3b599223cee557894",
            "e3134010d2274a9a847f545b46b083a1",
            "86caa214a7f6463d96b54ca4ef51254d",
            "f9aaf8e17cb647a3888a0ec597c2d66a",
            "1a0e82a332b149808c82363ae1c2320d",
            "4832c645c2794bf4af9bab4c0e8df11a",
            "1327754c2f9c46fcbb423ed2662ab26d",
            "e4fc70b897714adf89258b6149e67995",
            "3ac1d594568147eca00b0ee7837b2040",
            "0f5d74520fa849d0a03a6d0d1d1b9663",
            "a71d6650fff54fac979d1ff2f2685cb7",
            "548c37fbaacf43148f3f18e85498dda1",
            "64f6aa9255c84d86a6c2e7e3f410e6e5",
            "ab814e7ed4dc45b28a5cfd0cbbe91598",
            "c7f686288c2d4f72af66fc93022add71",
            "6fb5eb037c9e4840a3658d023442b07c",
            "36cecacaf8e249648c1d3c25d3057749",
            "252e7be1a1b14831ba1fdb24d77c6e1c",
            "dff1c2a67b154993a7ff0cb4db3a7646",
            "8315800528eb4955af3fdf13d40e70e2",
            "3f84c98e13bc4018a667c33ac1e8a6b9",
            "c770cf164c1b4517af3a5bbdb3aa6b48",
            "c986e7caee3b4afebf15e48626146d24",
            "e81177d036c14e1a85cc46c63cb008cc",
            "a4cc98ab9aa04a618a6ad7a6b3cb9b91",
            "a4eae702ae2b410691a3e9bca12d3a25",
            "3f03232b381d495eb4203a969ad3636c",
            "c3a79f60f3094866b6b2b261203fe60f",
            "00f3c969c0ab4ae581a0c85a6d4f8f49",
            "966a697e8da64798abf7c1e3c84598fc",
            "854c6d4cecd94c10b6031ff0d1866126",
            "a1cf889ac11a4f8296a45274aefb22f7",
            "39df6318ac8d4f259db9eda9d6cde5ab",
            "0176f0bb8c554425ac51860f2c3a1254",
            "6dfb5d3dad534573a50919dd8d7322ca",
            "ea763c88e38a46a7b049f879b08d078d",
            "ecaaf6fe83564f25bc21b9c880455767",
            "e02a5770175440da97981c4871f306aa"
          ]
        },
        "id": "ckWZzzyAlEuU",
        "outputId": "751f439f-e86f-4629-ee9f-53646294a76e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "addc7c801af64ce285e9eba9f94fa1fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4832c645c2794bf4af9bab4c0e8df11a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36cecacaf8e249648c1d3c25d3057749",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3a79f60f3094866b6b2b261203fe60f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def model_init_clf():\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"microsoft/deberta-base\", \n",
        "        num_labels=2, \n",
        "        id2label=id2label, \n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "    for param in model.deberta.embeddings.parameters():\n",
        "        param.requires_grad = False\n",
        "    for i in range(6):\n",
        "        for param in model.deberta.encoder.layer[i].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    model.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Linear(768, 1024),\n",
        "        torch.nn.BatchNorm1d(1024),\n",
        "        torch.nn.Dropout(0.2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(1024, 256),\n",
        "        torch.nn.BatchNorm1d(256),\n",
        "        torch.nn.Dropout(0.2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(256, 64),\n",
        "        torch.nn.BatchNorm1d(64),\n",
        "        torch.nn.Dropout(0.2),\n",
        "        torch.nn.ReLU(),  \n",
        "        torch.nn.Linear(64, 2),\n",
        "        torch.nn.Softmax(dim=-1)\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def model_init():\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"microsoft/deberta-base\", \n",
        "        num_labels=2, \n",
        "        id2label=id2label, \n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "    for param in model.deberta.embeddings.parameters():\n",
        "        param.requires_grad = False\n",
        "    for i in range(6):\n",
        "        for param in model.deberta.encoder.layer[i].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QW5zPfv_lEuU"
      },
      "outputs": [],
      "source": [
        "def tokenization(batched_text):\n",
        "    return tokenizer(\n",
        "        batched_text['text'], \n",
        "        padding = 'max_length', \n",
        "        truncation=True, \n",
        "        max_length = 512\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L5zAO8FYlEuU"
      },
      "outputs": [],
      "source": [
        "# define accuracy metrics\n",
        "def compute_metrics(pred):\n",
        "\n",
        "    preds, labels = pred\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='binary'\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hBT-w6wXlEuU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQP81lQNlEuU"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "b1f4ecb8da1c4f5ab76e81d9b22b619a",
            "58383934b54c41ce9cd931024b91dce3",
            "22e2701a5f514e91bffa750e864c07da",
            "b62268aef07c41508c6d84cf6792a1fd",
            "371257f55f654b06bdde97f16e3c651d",
            "024cbaea6a1a46e9a9fbf24eb7ce7134",
            "393e36bf70da41f0bd7a06a86c188b05",
            "10a14da24efc43cbac37aa949da1e9e2",
            "4ab09964ddf84901a4e8eeed7dd5fc15",
            "2bff2c437ee94994b7de483b9059254f",
            "f57af91095984ea4a4f6d2e99be1ced0",
            "cfe3ae963a904619862d4437e072ac60",
            "75efdb1bf9924cefbb412aabc1017ab4",
            "3fadcee66dee4ed281358fe8158d6128",
            "08df0af217df4183aeb7ad56e798c91f",
            "28fd670ba08d438d9496dee5afbbdb79",
            "e54ffdd5dd2c436d9ccb4e0b67d5ce63",
            "e9f2ca96c21349e5ad812db940138e9f",
            "e1428cf1309b4ef293c7c5ac9df69fa4",
            "0db2b24f343948d4b6b1a4d6c0cd343a",
            "aac0a38343a54ea29c70412ec954ccb1",
            "a55bc13378544e07821e26ccfd885f86",
            "ddb29e6807d949659bd07f84d84beb3e",
            "9d5990e616974dffae1ed3b54d066e82",
            "6d31333714634fd1afce4a16c4e96a1d",
            "21d48767fc7a4ec29892f5378fea1fb5",
            "8beffbfe6b1b4f489e848fa3b68eef9b",
            "a84bbfa0f3b7404682ac7dd6d8afc601",
            "18681bc17a8c478faaa20813ca0459f2",
            "23faab8cd4724763933cbaff7e69c677",
            "d4e47987a2c34878ad5d846a83aa7b38",
            "367a0a40d4a54fe5ae36854d5854ca10",
            "e960c4141bbd4d7dbd4fb435828e60a7",
            "9e7c9ddc9cda428982c885fd906f1332",
            "bf8baed112804f98870543e1f7b0cafe",
            "1c36b9d9cac743e09b7e1a29d556a092",
            "795be488d30948cfb552461017252dee",
            "f9a68aa823b44619995be54c5e9fb446",
            "bd88bc63467749a5a0fff8daedd873ec",
            "3319484db3f648aaa2d2059c7214cdbd",
            "7fbc4a2075304686bcb02d0da564c74f",
            "5b79acb1e4e141729562ce800c45687a",
            "5a29b2d6d2c84dd4b8d926ddcc6eefd6",
            "c94c0ea531ba424abd3a8c4eaeb6c6e9",
            "7b5be1ab8aec4b838f7b9860d7582cdf",
            "5567c2c7c75741019876efd10c5be80f",
            "e930f151724e44349552ba3c10f0e88f",
            "2320de8dada14694872ddff55d6e71d8",
            "ce7abf16161e40d1977058b16fa836af",
            "5b176d3bccc94fa6a27b2c91b5e6f416",
            "ac2f5851ec60469b90b4c3e41e4bc5bb",
            "d02ad016111b45ff8f57a3ce078837b1",
            "c5bc4d8fb0a24a778858dfb2f43ffb67",
            "794b1b17d1c24b81bef19067acbb0e5e",
            "dda2651ccc444d08bb6988d4354c58b3"
          ]
        },
        "id": "y8oKSLDllEuU",
        "outputId": "7bfd45d7-ba67-4f35-fffd-1b0f469fa69c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1f4ecb8da1c4f5ab76e81d9b22b619a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6700 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfe3ae963a904619862d4437e072ac60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddb29e6807d949659bd07f84d84beb3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/13983 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e7c9ddc9cda428982c885fd906f1332",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1675 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b5be1ab8aec4b838f7b9860d7582cdf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train)\n",
        ")\n",
        "\n",
        "pcl_df_train_train_aug = pcl_df_train_train_aug.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train_aug)\n",
        ")\n",
        "\n",
        "pcl_df_train_train_gpt = pcl_df_train_train_gpt.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_train_gpt)\n",
        ")\n",
        "\n",
        "\n",
        "pcl_df_train_dev = pcl_df_train_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train_dev)\n",
        ")\n",
        "\n",
        "pcl_df_dev = pcl_df_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_dev)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "B6hmkcf9lEuU"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "\n",
        "pcl_df_train_train_aug.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "\n",
        "pcl_df_train_train_gpt.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "pcl_df_train_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "pcl_df_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P5akw4NdlEuV"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pcl_df_train_train.rename_column(\"class\", \"label\")\n",
        "pcl_df_train_train_aug= pcl_df_train_train_aug.rename_column(\"class\", \"label\")\n",
        "pcl_df_train_train_gpt = pcl_df_train_train_gpt.rename_column(\"class\", \"label\")\n",
        "\n",
        "\n",
        "pcl_df_train_dev = pcl_df_train_dev.rename_column(\"class\", \"label\")\n",
        "pcl_df_dev = pcl_df_dev.rename_column(\"class\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6gsGAU-MlEuV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDAExOUQkCzU"
      },
      "source": [
        "### Train with best hyperparameters on the original train data (without modified classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qm-CwCECkCzU"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vu86Uy-xkCzU"
      },
      "outputs": [],
      "source": [
        "training_args_og = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-og'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873,
          "referenced_widgets": [
            "5a7aad6d1e1645a4a4d25173b7f5a3f2",
            "1188130d17cc425082260490e10ecdf5",
            "cb7f9eee64bc4dfbad8a372ff755350e",
            "fcfcf1f263e247988a567b60b5e00b92",
            "a2810b6628ce4f42a0ec5a020e7f1a97",
            "23271b5a30404bda943229099ea6125b",
            "5c0b3fd0247e49f3a23b7119775216db",
            "de7773de624f4714b181d95dc880a821",
            "fab9a220eba648df890362973b48b0da",
            "920b3c9577a74feaa8a88d055a3380e4",
            "499fdeaeb0be4cffae0653b1a519d134"
          ]
        },
        "id": "zq0dk_WhkCzU",
        "outputId": "bbecb915-a761-4960-b7df-69862f10ff0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a7aad6d1e1645a4a4d25173b7f5a3f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/559M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_og = Trainer(\n",
        "        args=training_args_og,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AcSlDQf0kCzU",
        "outputId": "bc4b13fd-bd73-464d-af76-819c83c05790"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6700\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 260\n",
            "  Number of trainable parameters = 50983682\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 10:03, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.241042</td>\n",
              "      <td>0.905672</td>\n",
              "      <td>0.150538</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.082840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.226136</td>\n",
              "      <td>0.909851</td>\n",
              "      <td>0.584022</td>\n",
              "      <td>0.546392</td>\n",
              "      <td>0.627219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.191363</td>\n",
              "      <td>0.925373</td>\n",
              "      <td>0.485597</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.349112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.184284</td>\n",
              "      <td>0.928955</td>\n",
              "      <td>0.560886</td>\n",
              "      <td>0.745098</td>\n",
              "      <td>0.449704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.186330</td>\n",
              "      <td>0.928955</td>\n",
              "      <td>0.554307</td>\n",
              "      <td>0.755102</td>\n",
              "      <td>0.437870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-52\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-52/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-52/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-104\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-104/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-104/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-156\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-156/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-156/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-208\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-208/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-208/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-260\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-260/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-260/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-104 (score: 0.5840220385674931).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=260, training_loss=0.2251452115865854, metrics={'train_runtime': 610.0298, 'train_samples_per_second': 54.915, 'train_steps_per_second': 0.426, 'total_flos': 1.0257529279905792e+16, 'train_loss': 0.2251452115865854, 'epoch': 4.99})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_og.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "-NelUsR8kCzU",
        "outputId": "eda28388-8c7b-4ffc-bce0-357380e3650c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2261359840631485,\n",
              " 'eval_accuracy': 0.9098507462686567,\n",
              " 'eval_f1': 0.5840220385674931,\n",
              " 'eval_precision': 0.5463917525773195,\n",
              " 'eval_recall': 0.6272189349112426,\n",
              " 'eval_runtime': 8.3126,\n",
              " 'eval_samples_per_second': 201.501,\n",
              " 'eval_steps_per_second': 12.631,\n",
              " 'epoch': 4.99}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_og.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3YhWoCakCzU"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "nBoMx6E4kCzU",
        "outputId": "695cbc6c-1422-4afc-9204-cf2795775c60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_og, dev_set_labels_og, dev_set_metrics_og = trainer_og.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSKolWelkCzU",
        "outputId": "9e2d7c09-e221-4129-e76b-db64aa5a066c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.2377750724554062,\n",
              " 'dev_accuracy': 0.9011461318051576,\n",
              " 'dev_f1': 0.5450549450549451,\n",
              " 'dev_precision': 0.484375,\n",
              " 'dev_recall': 0.6231155778894473,\n",
              " 'dev_runtime': 10.4557,\n",
              " 'dev_samples_per_second': 200.273,\n",
              " 'dev_steps_per_second': 12.529}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_og"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "sAHcEOejkCzU"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_og = np.argmax(dev_set_preds_og)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t38j1kUytZQy"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTtVwSORtZQ6",
        "outputId": "bfccc218-ded5-4573-96f5-e1bba705c30d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_og\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_og.save_model(f'{results_folder}/deberta_frozen_og')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb6o_VWPlEuW"
      },
      "source": [
        "### Train with best hyperparameters on the original train data (without modified classifier) - grad accum step = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DcCVTnH8lEuW"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 2\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnKuPaIRlEuW",
        "outputId": "56f60b7c-1b4a-44ad-caf7-f2077bafd111"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_og_2 = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-2'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1Hty6hGlEuW",
        "outputId": "d1fca931-f2ef-489c-c0b0-1b860423416e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_og_2 = Trainer(\n",
        "        args=training_args_og_2,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9xY2h-JrlEuW",
        "outputId": "fafc5773-97ae-402e-cb66-32de0e3ad527"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6700\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 1045\n",
            "  Number of trainable parameters = 50983682\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1045' max='1045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1045/1045 08:53, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.219400</td>\n",
              "      <td>0.189348</td>\n",
              "      <td>0.922985</td>\n",
              "      <td>0.547368</td>\n",
              "      <td>0.672414</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.181461</td>\n",
              "      <td>0.924776</td>\n",
              "      <td>0.582781</td>\n",
              "      <td>0.661654</td>\n",
              "      <td>0.520710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.141300</td>\n",
              "      <td>0.188476</td>\n",
              "      <td>0.921791</td>\n",
              "      <td>0.618076</td>\n",
              "      <td>0.609195</td>\n",
              "      <td>0.627219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.103300</td>\n",
              "      <td>0.214919</td>\n",
              "      <td>0.924776</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.654676</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.084800</td>\n",
              "      <td>0.226444</td>\n",
              "      <td>0.929552</td>\n",
              "      <td>0.611842</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.550296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-209\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-209/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-209/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-209/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-209/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-418\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-418/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-418/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-418/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-418/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-627\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-627/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-627/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-627/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-627/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-836\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-836/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-836/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-836/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-836/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1045\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-627 (score: 0.6180758017492712).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1045, training_loss=0.15721534884147095, metrics={'train_runtime': 533.6003, 'train_samples_per_second': 62.781, 'train_steps_per_second': 1.958, 'total_flos': 1.0267340403081216e+16, 'train_loss': 0.15721534884147095, 'epoch': 5.0})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_og_2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "_msT_dXjlEuW",
        "outputId": "7fcf9b48-4b49-4758-d583-f448e499ec5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.18847616016864777,\n",
              " 'eval_accuracy': 0.9217910447761194,\n",
              " 'eval_f1': 0.6180758017492712,\n",
              " 'eval_precision': 0.6091954022988506,\n",
              " 'eval_recall': 0.6272189349112426,\n",
              " 'eval_runtime': 8.2327,\n",
              " 'eval_samples_per_second': 203.457,\n",
              " 'eval_steps_per_second': 12.754,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_og_2.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyg8tzSxlEuX"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "c2GH4weSlEuX",
        "outputId": "ae58280f-3332-47c7-e6e2-29180806acd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_og_2, dev_set_labels_og_2, dev_set_metrics_og_2 = trainer_og_2.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOfLLcA1lEuX",
        "outputId": "6190a842-48c6-4edd-afb9-37b717b9a783"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.1874750256538391,\n",
              " 'dev_accuracy': 0.9250238777459407,\n",
              " 'dev_f1': 0.6252983293556086,\n",
              " 'dev_precision': 0.5954545454545455,\n",
              " 'dev_recall': 0.6582914572864321,\n",
              " 'dev_runtime': 10.4208,\n",
              " 'dev_samples_per_second': 200.945,\n",
              " 'dev_steps_per_second': 12.571}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_og_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "QUn9CsNllEuX"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_og_2 = np.argmax(dev_set_preds_og_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYEcYsGktvw3"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHKQAWMetvw3",
        "outputId": "e65d8445-7334-4895-8bff-b440c6ef7f2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_og_2\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og_2/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og_2/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og_2/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_og_2/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_og_2.save_model(f'{results_folder}/deberta_frozen_og_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIip7IHxSo3L"
      },
      "source": [
        "### Train with best hyperparameters on the original train data (with modified classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XfsM4j1fSo3L"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKxRjll3So3L",
        "outputId": "f5cbbd36-54fa-48a1-bad6-9c63fbdae1c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_clf = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-clf'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEdFDsOgSo3M",
        "outputId": "070b36a2-f8cd-4e08-91fe-53f867830e00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_clf = Trainer(\n",
        "        args=training_args_clf,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fqjahxXiSo3M",
        "outputId": "86e0111b-71a5-4bb3-8a86-34e1af709b1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6700\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 260\n",
            "  Number of trainable parameters = 52051266\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 08:46, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.625534</td>\n",
              "      <td>0.882985</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.005917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.655400</td>\n",
              "      <td>0.636259</td>\n",
              "      <td>0.880597</td>\n",
              "      <td>0.099099</td>\n",
              "      <td>0.207547</td>\n",
              "      <td>0.065089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.655400</td>\n",
              "      <td>0.616467</td>\n",
              "      <td>0.724776</td>\n",
              "      <td>0.285271</td>\n",
              "      <td>0.193277</td>\n",
              "      <td>0.544379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.610887</td>\n",
              "      <td>0.871045</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.216867</td>\n",
              "      <td>0.106509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.604085</td>\n",
              "      <td>0.874627</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.233766</td>\n",
              "      <td>0.106509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-52\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-52/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-52/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-52/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-104\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-104/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-104/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-104/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-156\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-156/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-156/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-156/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-208\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-208/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-208/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-208/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-260\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-260/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-260/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-260/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-156 (score: 0.2852713178294574).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=260, training_loss=0.6440114534818209, metrics={'train_runtime': 527.8301, 'train_samples_per_second': 63.467, 'train_steps_per_second': 0.493, 'total_flos': 1.036725218131968e+16, 'train_loss': 0.6440114534818209, 'epoch': 4.99})"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_clf.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "6yFILhmgSo3M",
        "outputId": "7be238e7-52fe-427c-e678-57b02e9e9cc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6164670586585999,\n",
              " 'eval_accuracy': 0.724776119402985,\n",
              " 'eval_f1': 0.2852713178294574,\n",
              " 'eval_precision': 0.19327731092436976,\n",
              " 'eval_recall': 0.5443786982248521,\n",
              " 'eval_runtime': 8.2747,\n",
              " 'eval_samples_per_second': 202.425,\n",
              " 'eval_steps_per_second': 12.689,\n",
              " 'epoch': 4.99}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_clf.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xREQqyk3So3M"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "_WYvGDbbSo3M",
        "outputId": "02d51ab5-9445-4a9e-dca5-5b4750cf330b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_clf, dev_set_labels_clf, dev_set_metrics_clf = trainer_clf.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRVwi44ESo3M",
        "outputId": "ed4558c5-b495-4a5e-9040-34826bd31df4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.6174400448799133,\n",
              " 'dev_accuracy': 0.723018147086915,\n",
              " 'dev_f1': 0.2676767676767677,\n",
              " 'dev_precision': 0.178752107925801,\n",
              " 'dev_recall': 0.5326633165829145,\n",
              " 'dev_runtime': 10.4247,\n",
              " 'dev_samples_per_second': 200.869,\n",
              " 'dev_steps_per_second': 12.566}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "orejXd-KSo3M"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_clf = np.argmax(dev_set_preds_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7X2cbzpSo3M"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7CgPs5DSo3M",
        "outputId": "e6abdb10-f673-4824-ef83-7b11ff69e73e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_clf\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_clf.save_model(f'{results_folder}/deberta_frozen_clf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0gDmkwfSo3M"
      },
      "source": [
        "### Train with best hyperparameters on the original train data (with modified classifier) - grad accum steps = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "K-M9mbXVSo3M"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 2\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbj9vED8So3M",
        "outputId": "ac95f6d5-a557-4f9b-a34a-96288ee499fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_clf_2 = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-clf-2'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIFZDQifSo3N",
        "outputId": "3a1cc24e-172c-47d4-9c85-cf6b2e6fe79f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_clf_2 = Trainer(\n",
        "        args=training_args_clf_2,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d5fI5TvLSo3N",
        "outputId": "34225b3b-7555-4b41-b354-07e42f062b44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6700\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 1045\n",
            "  Number of trainable parameters = 52051266\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1045' max='1045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1045/1045 09:02, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.631900</td>\n",
              "      <td>0.612852</td>\n",
              "      <td>0.804179</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.303704</td>\n",
              "      <td>0.727811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.566900</td>\n",
              "      <td>0.560483</td>\n",
              "      <td>0.878806</td>\n",
              "      <td>0.545861</td>\n",
              "      <td>0.438849</td>\n",
              "      <td>0.721893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.516400</td>\n",
              "      <td>0.541161</td>\n",
              "      <td>0.886567</td>\n",
              "      <td>0.572072</td>\n",
              "      <td>0.461818</td>\n",
              "      <td>0.751479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.504300</td>\n",
              "      <td>0.512947</td>\n",
              "      <td>0.899701</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.502041</td>\n",
              "      <td>0.727811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.494600</td>\n",
              "      <td>0.508892</td>\n",
              "      <td>0.917015</td>\n",
              "      <td>0.612813</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.650888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-209\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-209/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-209/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-209/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-209/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-418\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-418/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-418/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-418/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-418/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-627\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-627/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-627/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-627/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-627/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-836\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-836/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-836/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-836/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-836/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1045\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1045/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-1045 (score: 0.6128133704735376).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1045, training_loss=0.5505819749604002, metrics={'train_runtime': 542.9896, 'train_samples_per_second': 61.695, 'train_steps_per_second': 1.925, 'total_flos': 1.037716825227264e+16, 'train_loss': 0.5505819749604002, 'epoch': 5.0})"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_clf_2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "a5cpS3-rSo3N",
        "outputId": "53dbd3fb-6d2c-4c00-9325-2a38dde73496"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5088923573493958,\n",
              " 'eval_accuracy': 0.9170149253731343,\n",
              " 'eval_f1': 0.6128133704735376,\n",
              " 'eval_precision': 0.5789473684210527,\n",
              " 'eval_recall': 0.650887573964497,\n",
              " 'eval_runtime': 8.2565,\n",
              " 'eval_samples_per_second': 202.87,\n",
              " 'eval_steps_per_second': 12.717,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_clf_2.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh36HmjuSo3N"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "laDuU9QuSo3N",
        "outputId": "c8f5dcc2-c1ee-4f57-f49e-da693fac74e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_clf_2, dev_set_labels_clf_2, dev_set_metrics_clf_2 = trainer_clf_2.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ_2qzjPSo3N",
        "outputId": "049eb646-fc70-4377-e35f-4584de68fe69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.5138863325119019,\n",
              " 'dev_accuracy': 0.9097421203438395,\n",
              " 'dev_f1': 0.5827814569536424,\n",
              " 'dev_precision': 0.5196850393700787,\n",
              " 'dev_recall': 0.6633165829145728,\n",
              " 'dev_runtime': 10.4959,\n",
              " 'dev_samples_per_second': 199.506,\n",
              " 'dev_steps_per_second': 12.481}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_clf_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Lui9XRuiSo3N"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_clf_2 = np.argmax(dev_set_preds_clf_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWlntl8TSo3N"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upWS21zISo3N",
        "outputId": "af1e05d9-c414-4695-d99e-1035325357bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_clf_2\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf_2/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf_2/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf_2/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_clf_2/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_clf_2.save_model(f'{results_folder}/deberta_frozen_clf_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPMGsxoKIc2L"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data (without chatgpt data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "vGFOCEZ9Ic2L"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3cAjJmyIc2L",
        "outputId": "5d4b9941-aa20-46cd-9789-15f0edc05d78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_aug = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-aug-run2'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmTnLlaGIc2L",
        "outputId": "5be9edd7-3e59-484f-f4a4-e29f6c7b8ab1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_aug = Trainer(\n",
        "        args=training_args_aug,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_aug,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EWCLlywyIc2M",
        "outputId": "83f24aa1-a5ca-4f93-c5ee-c4f66d723e83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12150\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 475\n",
            "  Number of trainable parameters = 50983682\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 15:00, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.233965</td>\n",
              "      <td>0.905075</td>\n",
              "      <td>0.541787</td>\n",
              "      <td>0.528090</td>\n",
              "      <td>0.556213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.320100</td>\n",
              "      <td>0.178831</td>\n",
              "      <td>0.925373</td>\n",
              "      <td>0.603175</td>\n",
              "      <td>0.650685</td>\n",
              "      <td>0.562130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.160700</td>\n",
              "      <td>0.174194</td>\n",
              "      <td>0.933731</td>\n",
              "      <td>0.640777</td>\n",
              "      <td>0.707143</td>\n",
              "      <td>0.585799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.118300</td>\n",
              "      <td>0.191051</td>\n",
              "      <td>0.927164</td>\n",
              "      <td>0.641176</td>\n",
              "      <td>0.637427</td>\n",
              "      <td>0.644970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.086200</td>\n",
              "      <td>0.199860</td>\n",
              "      <td>0.934328</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.712230</td>\n",
              "      <td>0.585799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-95\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-95/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-95/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-95/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-95/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-190\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-190/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-190/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-190/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-190/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-285\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-285/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-285/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-285/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-285/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-380\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-380/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-380/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-380/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-380/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-475\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-475/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-475/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-475/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-475/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-475 (score: 0.6428571428571428).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=475, training_loss=0.15530719054372688, metrics={'train_runtime': 902.3503, 'train_samples_per_second': 67.324, 'train_steps_per_second': 0.526, 'total_flos': 1.8625804153344e+16, 'train_loss': 0.15530719054372688, 'epoch': 5.0})"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_aug.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "24ISWa3_Ic2M",
        "outputId": "98b2fc37-c8dd-457f-f75a-4c4011b42c9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.1998598724603653,\n",
              " 'eval_accuracy': 0.9343283582089552,\n",
              " 'eval_f1': 0.6428571428571428,\n",
              " 'eval_precision': 0.7122302158273381,\n",
              " 'eval_recall': 0.5857988165680473,\n",
              " 'eval_runtime': 8.31,\n",
              " 'eval_samples_per_second': 201.564,\n",
              " 'eval_steps_per_second': 12.635,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_aug.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh8hESJzIc2M"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "zU3HV55WIc2M",
        "outputId": "d481c761-36f3-42cc-acef-d01f8177d587"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_aug, dev_set_labels_aug, dev_set_metrics_aug = trainer_aug.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVk3Z0efIc2M",
        "outputId": "e385ceca-a401-45e4-d73a-b450e5a0d14f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.2281123697757721,\n",
              " 'dev_accuracy': 0.9235912129894938,\n",
              " 'dev_f1': 0.5721925133689839,\n",
              " 'dev_precision': 0.6114285714285714,\n",
              " 'dev_recall': 0.5376884422110553,\n",
              " 'dev_runtime': 10.5199,\n",
              " 'dev_samples_per_second': 199.05,\n",
              " 'dev_steps_per_second': 12.453}"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "VjfGTx8GIc2M"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_aug = np.argmax(dev_set_preds_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYmTVjcnlEuX"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnf8Z3wglEuX",
        "outputId": "d85d81da-ba53-44a3-bd83-0c023c227f72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_aug_run2\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_run2/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_run2/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_run2/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_run2/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_aug.save_model(f'{results_folder}/deberta_frozen_aug_run2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm85xMk8So3O"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data (without chatgpt data) - gradient accumulation step = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "aU3sOHtiSo3O"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 2\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owfo2utSSo3O",
        "outputId": "ba3bacee-4379-49c6-9d20-dc831a0ad783"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_aug_2 = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-aug-2'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YiqpaohSo3O",
        "outputId": "cd5a0040-86a9-4579-8ff5-e1be093c0123"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_aug_2 = Trainer(\n",
        "        args=training_args_aug_2,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_aug,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J_azKF-cSo3O",
        "outputId": "5aac9c72-fa6a-4677-9ad2-a64fb761b2de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12150\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 1900\n",
            "  Number of trainable parameters = 50983682\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='837' max='1900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 837/1900 06:43 < 08:33, 2.07 it/s, Epoch 2.20/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.174500</td>\n",
              "      <td>0.192528</td>\n",
              "      <td>0.919403</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.593407</td>\n",
              "      <td>0.639053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.192449</td>\n",
              "      <td>0.922388</td>\n",
              "      <td>0.603659</td>\n",
              "      <td>0.622642</td>\n",
              "      <td>0.585799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-380\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-380/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-380/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-380/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-380/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-760\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-760/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-760/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-760/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-760/special_tokens_map.json\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1900' max='1900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1900/1900 15:23, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.174500</td>\n",
              "      <td>0.192528</td>\n",
              "      <td>0.919403</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.593407</td>\n",
              "      <td>0.639053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.192449</td>\n",
              "      <td>0.922388</td>\n",
              "      <td>0.603659</td>\n",
              "      <td>0.622642</td>\n",
              "      <td>0.585799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>0.323385</td>\n",
              "      <td>0.926567</td>\n",
              "      <td>0.562278</td>\n",
              "      <td>0.705357</td>\n",
              "      <td>0.467456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.023300</td>\n",
              "      <td>0.386253</td>\n",
              "      <td>0.925970</td>\n",
              "      <td>0.592105</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.532544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.013800</td>\n",
              "      <td>0.428724</td>\n",
              "      <td>0.925970</td>\n",
              "      <td>0.575342</td>\n",
              "      <td>0.682927</td>\n",
              "      <td>0.497041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1140\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1140/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1140/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1140/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1140/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1520\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1520/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1520/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1520/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1520/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1900\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1900/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1900/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1900/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-380 (score: 0.6153846153846154).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1900, training_loss=0.09108196082868074, metrics={'train_runtime': 923.5536, 'train_samples_per_second': 65.779, 'train_steps_per_second': 2.057, 'total_flos': 1.8625804153344e+16, 'train_loss': 0.09108196082868074, 'epoch': 5.0})"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_aug_2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "IYTozrOISo3O",
        "outputId": "2277311d-da04-4b0f-a46c-65b495706cc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.19252756237983704,\n",
              " 'eval_accuracy': 0.9194029850746268,\n",
              " 'eval_f1': 0.6153846153846154,\n",
              " 'eval_precision': 0.5934065934065934,\n",
              " 'eval_recall': 0.6390532544378699,\n",
              " 'eval_runtime': 8.2672,\n",
              " 'eval_samples_per_second': 202.607,\n",
              " 'eval_steps_per_second': 12.701,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_aug_2.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omi9fJ0wSo3O"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "dJaboRbvSo3O",
        "outputId": "ecb1441f-367a-4de4-97ce-01b383e1b4c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_aug_2, dev_set_labels_aug_2, dev_set_metrics_aug_2 = trainer_aug_2.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGMYFxwfpAHD",
        "outputId": "aaaf1d27-b212-48eb-ff86-1be09c454526"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.20923367142677307,\n",
              " 'dev_accuracy': 0.9145176695319962,\n",
              " 'dev_f1': 0.597752808988764,\n",
              " 'dev_precision': 0.540650406504065,\n",
              " 'dev_recall': 0.6683417085427136,\n",
              " 'dev_runtime': 10.5095,\n",
              " 'dev_samples_per_second': 199.248,\n",
              " 'dev_steps_per_second': 12.465}"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_aug_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tLBEHzEeSo3P"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_aug_2 = np.argmax(dev_set_preds_aug_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VWv_egpSo3P"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhpXrRr7So3P",
        "outputId": "b01d7f1b-6871-4bcb-fdc9-889c684c1d6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_aug_2\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_2/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_2/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_2/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_aug_2/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_aug_2.save_model(f'{results_folder}/deberta_frozen_aug_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDeeJ6XnDo13"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data + chatgpt data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Xre1yKwdDo13"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKTNvT0ZDo14",
        "outputId": "a293bc13-7751-421a-ea38-238e57d71f15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_gpt = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-gpt'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vwcSqXHDo14",
        "outputId": "5eaff234-6468-492f-82cf-2bb160b4a120"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_gpt = Trainer(\n",
        "        args=training_args_gpt,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_gpt,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kDCzUeziDo14",
        "outputId": "257ef140-b2d7-4417-df11-a0c59b372c62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13983\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 545\n",
            "  Number of trainable parameters = 50983682\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='545' max='545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [545/545 18:21, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.352100</td>\n",
              "      <td>0.312298</td>\n",
              "      <td>0.897313</td>\n",
              "      <td>0.022727</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.011834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.203500</td>\n",
              "      <td>0.214098</td>\n",
              "      <td>0.902687</td>\n",
              "      <td>0.089385</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.047337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.155400</td>\n",
              "      <td>0.187606</td>\n",
              "      <td>0.924776</td>\n",
              "      <td>0.507812</td>\n",
              "      <td>0.747126</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.130300</td>\n",
              "      <td>0.183998</td>\n",
              "      <td>0.922985</td>\n",
              "      <td>0.603077</td>\n",
              "      <td>0.628205</td>\n",
              "      <td>0.579882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.108200</td>\n",
              "      <td>0.182163</td>\n",
              "      <td>0.927761</td>\n",
              "      <td>0.605863</td>\n",
              "      <td>0.673913</td>\n",
              "      <td>0.550296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-109\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-109/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-109/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-109/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-109/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-218\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-218/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-218/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-218/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-218/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-327\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-327/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-327/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-327/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-327/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-436\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-436/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-436/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-436/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-436/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-545\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-545/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-545/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-545/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-545/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-545 (score: 0.6058631921824105).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=545, training_loss=0.1817144253932008, metrics={'train_runtime': 1103.1269, 'train_samples_per_second': 63.379, 'train_steps_per_second': 0.494, 'total_flos': 2.142626662472909e+16, 'train_loss': 0.1817144253932008, 'epoch': 5.0})"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_gpt.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3fIAgxJDo14"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "5rK5Vqx6Do14",
        "outputId": "7dd28c72-b464-48f6-b4c1-259a1b85d70b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.18216276168823242,\n",
              " 'eval_accuracy': 0.9277611940298508,\n",
              " 'eval_f1': 0.6058631921824105,\n",
              " 'eval_precision': 0.6739130434782609,\n",
              " 'eval_recall': 0.5502958579881657,\n",
              " 'eval_runtime': 8.3305,\n",
              " 'eval_samples_per_second': 201.069,\n",
              " 'eval_steps_per_second': 12.604,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_gpt.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT6wPdn4Do14"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "uRYVzLntDo14",
        "outputId": "cbb479f7-3110-4550-dd5e-73d8b915d768"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_gpt, dev_set_labels_gpt, dev_set_metrics_gpt = trainer_gpt.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp6D9GBUDo14",
        "outputId": "d46bb94b-8567-4a93-ff81-a3f3547a9513"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.1997695416212082,\n",
              " 'dev_accuracy': 0.9231136580706781,\n",
              " 'dev_f1': 0.5751978891820579,\n",
              " 'dev_precision': 0.6055555555555555,\n",
              " 'dev_recall': 0.5477386934673367,\n",
              " 'dev_runtime': 10.4385,\n",
              " 'dev_samples_per_second': 200.603,\n",
              " 'dev_steps_per_second': 12.55}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_gpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "r2yfM82CDo14"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_gpt = np.argmax(dev_set_preds_gpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LFVhN4WiY7d"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyavUSqeiY7e",
        "outputId": "e73cdbaa-c497-4401-df68-9919d4940b45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_gpt\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_gpt.save_model(f'{results_folder}/deberta_frozen_gpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "hzAJLwvpig-5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsMQ3tEaSo3Q"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data + chatgpt data (grad accumulation step = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "yKqx2CZySo3Q"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 2\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhVlqKU-So3Q",
        "outputId": "2c82a3d4-8f35-46c1-ccea-56e483b1df40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_gpt_2 = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-gpt-2-run2'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hex1rfYvSo3Q",
        "outputId": "2e1cef78-ea0f-4e61-f7a4-a09f24455dfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_gpt_2 = Trainer(\n",
        "        args=training_args_gpt_2,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_gpt,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sMa8R1WmSo3Q",
        "outputId": "2c90470f-e2ff-4697-c37f-d182fc70c873"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13983\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 2185\n",
            "  Number of trainable parameters = 50983682\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2185' max='2185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2185/2185 17:40, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.148400</td>\n",
              "      <td>0.187943</td>\n",
              "      <td>0.922388</td>\n",
              "      <td>0.560811</td>\n",
              "      <td>0.653543</td>\n",
              "      <td>0.491124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.089000</td>\n",
              "      <td>0.209641</td>\n",
              "      <td>0.927761</td>\n",
              "      <td>0.625387</td>\n",
              "      <td>0.655844</td>\n",
              "      <td>0.597633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.032100</td>\n",
              "      <td>0.359288</td>\n",
              "      <td>0.916418</td>\n",
              "      <td>0.593023</td>\n",
              "      <td>0.582857</td>\n",
              "      <td>0.603550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.023500</td>\n",
              "      <td>0.409433</td>\n",
              "      <td>0.926567</td>\n",
              "      <td>0.619195</td>\n",
              "      <td>0.649351</td>\n",
              "      <td>0.591716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.010100</td>\n",
              "      <td>0.431822</td>\n",
              "      <td>0.925970</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.550296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-437\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-437/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-437/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-437/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-437/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-874\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-874/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-874/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-874/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-874/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1311\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1748\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-2185\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-874 (score: 0.6253869969040248).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2185, training_loss=0.08197649164930906, metrics={'train_runtime': 1060.6336, 'train_samples_per_second': 65.918, 'train_steps_per_second': 2.06, 'total_flos': 2.143577115030528e+16, 'train_loss': 0.08197649164930906, 'epoch': 5.0})"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_gpt_2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "N3Z9Ux60So3Q",
        "outputId": "0fbec01e-f8ce-42cd-9936-88fdfec56a09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.20964111387729645,\n",
              " 'eval_accuracy': 0.9277611940298508,\n",
              " 'eval_f1': 0.6253869969040248,\n",
              " 'eval_precision': 0.6558441558441559,\n",
              " 'eval_recall': 0.5976331360946746,\n",
              " 'eval_runtime': 8.2874,\n",
              " 'eval_samples_per_second': 202.115,\n",
              " 'eval_steps_per_second': 12.67,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_gpt_2.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtHbfNfESo3Q"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "NYYQm95_So3Q",
        "outputId": "e6cc3d28-456a-4752-e384-17988d3a1ef5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_gpt_2, dev_set_labels_gpt_2, dev_set_metrics_gpt_2 = trainer_gpt_2.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AcVMQEoSo3Q",
        "outputId": "50760ecb-cb33-43dc-81c7-dea070346c3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.23594646155834198,\n",
              " 'dev_accuracy': 0.9149952244508118,\n",
              " 'dev_f1': 0.5594059405940593,\n",
              " 'dev_precision': 0.551219512195122,\n",
              " 'dev_recall': 0.5678391959798995,\n",
              " 'dev_runtime': 10.5423,\n",
              " 'dev_samples_per_second': 198.628,\n",
              " 'dev_steps_per_second': 12.426}"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_gpt_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "q5GPxu8wSo3R"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_gpt_2 = np.argmax(dev_set_preds_gpt_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VggR9PYSo3R"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eKp5DS-So3R",
        "outputId": "9c7557b2-e51d-46f0-d437-db565fa6d72d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_2_run2\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_2_run2/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_2_run2/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_2_run2/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_2_run2/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_gpt_2.save_model(f'{results_folder}/deberta_frozen_gpt_2_run2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2aWjETFytVp"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data + chatgpt data (with modified classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "pGuAqpfQytVp"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 8\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYkwl0wYytVp",
        "outputId": "1063250a-84e5-4b32-aba3-5ed6b54c54a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_gpt_clf = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-gpt-clf'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_i7kID_ytVp",
        "outputId": "b768a492-ae28-4f40-b35b-f40222349db1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_gpt_clf = Trainer(\n",
        "        args=training_args_gpt_clf,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_gpt,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VcyApIzyytVq",
        "outputId": "b9a47345-8c72-4dd8-8421-dc2535d2d84b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13983\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 545\n",
            "  Number of trainable parameters = 52051266\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='545' max='545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [545/545 17:13, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.536300</td>\n",
              "      <td>0.459893</td>\n",
              "      <td>0.887761</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.193548</td>\n",
              "      <td>0.035503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.451200</td>\n",
              "      <td>0.425470</td>\n",
              "      <td>0.902090</td>\n",
              "      <td>0.078652</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.041420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.430600</td>\n",
              "      <td>0.413329</td>\n",
              "      <td>0.912836</td>\n",
              "      <td>0.391667</td>\n",
              "      <td>0.661972</td>\n",
              "      <td>0.278107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.418200</td>\n",
              "      <td>0.408445</td>\n",
              "      <td>0.923582</td>\n",
              "      <td>0.549296</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.411000</td>\n",
              "      <td>0.406648</td>\n",
              "      <td>0.924179</td>\n",
              "      <td>0.588997</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-109\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-109/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-109/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-109/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-109/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-218\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-218/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-218/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-218/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-218/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-327\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-327/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-327/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-327/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-327/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-436\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-436/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-436/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-436/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-436/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-545\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-545/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-545/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-545/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-545/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-545 (score: 0.5889967637540453).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=545, training_loss=0.4460966092730881, metrics={'train_runtime': 1034.8507, 'train_samples_per_second': 67.56, 'train_steps_per_second': 0.527, 'total_flos': 2.165545945239552e+16, 'train_loss': 0.4460966092730881, 'epoch': 5.0})"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_gpt_clf.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "mtUzHYxwytVq",
        "outputId": "bc782fa2-de84-49d6-f229-3c4f48b2de43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.40664806962013245,\n",
              " 'eval_accuracy': 0.924179104477612,\n",
              " 'eval_f1': 0.5889967637540453,\n",
              " 'eval_precision': 0.65,\n",
              " 'eval_recall': 0.5384615384615384,\n",
              " 'eval_runtime': 8.2917,\n",
              " 'eval_samples_per_second': 202.009,\n",
              " 'eval_steps_per_second': 12.663,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_gpt_clf.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuVNgoRPytVq"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "f-v12NILytVq",
        "outputId": "d7bf012d-88cb-453b-e16d-7d61babca81b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_gpt_clf, dev_set_labels_gpt_clf, dev_set_metrics_gpt_clf = trainer_gpt_clf.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt5X28hSytVq",
        "outputId": "345ba0a1-029e-4a46-fd55-769b0c555dfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.40973177552223206,\n",
              " 'dev_accuracy': 0.9212034383954155,\n",
              " 'dev_f1': 0.5691906005221932,\n",
              " 'dev_precision': 0.592391304347826,\n",
              " 'dev_recall': 0.5477386934673367,\n",
              " 'dev_runtime': 10.4887,\n",
              " 'dev_samples_per_second': 199.644,\n",
              " 'dev_steps_per_second': 12.49}"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_gpt_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Q4AlQ10uytVq"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_gpt_clf = np.argmax(dev_set_preds_gpt_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpRqREuiytVq"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAYOq8NIytVq",
        "outputId": "f73703b8-85f1-4828-9394-d9080373c5b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_gpt_clf.save_model(f'{results_folder}/deberta_frozen_gpt_clf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_GPTpBRytVq"
      },
      "source": [
        "### Train with best hyperparameters on the augmented train data + chatgpt data (with modified classifier) (grad accumulation step = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "QkweHBxjytVq"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 2\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nUIdPm9ytVq",
        "outputId": "750b32ef-9efd-4093-cb6b-c29acddebf69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_gpt_clf_2 = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-frozen-gpt-clf-2-run2'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZPllRAGytVq",
        "outputId": "ace70426-89b3-4ca0-ada7-ccf2ab74522a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_gpt_clf_2 = Trainer(\n",
        "        args=training_args_gpt_clf_2,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train_train_gpt,\n",
        "        eval_dataset=pcl_df_train_dev,\n",
        "        model_init=model_init_clf,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iZHw-cU0ytVq",
        "outputId": "f4b6a36c-fb75-47a7-b04a-aefa77c59bfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13983\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 2185\n",
            "  Number of trainable parameters = 52051266\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2185' max='2185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2185/2185 17:49, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.423100</td>\n",
              "      <td>0.407640</td>\n",
              "      <td>0.922985</td>\n",
              "      <td>0.520446</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.414201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.393800</td>\n",
              "      <td>0.396195</td>\n",
              "      <td>0.925373</td>\n",
              "      <td>0.485597</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.349112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.377700</td>\n",
              "      <td>0.391949</td>\n",
              "      <td>0.930149</td>\n",
              "      <td>0.611296</td>\n",
              "      <td>0.696970</td>\n",
              "      <td>0.544379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.361200</td>\n",
              "      <td>0.392733</td>\n",
              "      <td>0.928358</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.728972</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.358400</td>\n",
              "      <td>0.388912</td>\n",
              "      <td>0.932537</td>\n",
              "      <td>0.608997</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.520710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-437\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-437/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-437/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-437/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-437/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-874\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-874/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-874/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-874/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-874/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1311\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1311/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1748\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1748/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-2185\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-2185/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-1311 (score: 0.611295681063123).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2185, training_loss=0.39435667391499885, metrics={'train_runtime': 1069.5302, 'train_samples_per_second': 65.37, 'train_steps_per_second': 2.043, 'total_flos': 2.16650656461312e+16, 'train_loss': 0.39435667391499885, 'epoch': 5.0})"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_gpt_clf_2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "GUNRxowXytVr",
        "outputId": "399d7a36-22b4-4cff-a37a-6014043de5c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1675\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.39194872975349426,\n",
              " 'eval_accuracy': 0.9301492537313433,\n",
              " 'eval_f1': 0.611295681063123,\n",
              " 'eval_precision': 0.696969696969697,\n",
              " 'eval_recall': 0.5443786982248521,\n",
              " 'eval_runtime': 8.3108,\n",
              " 'eval_samples_per_second': 201.545,\n",
              " 'eval_steps_per_second': 12.634,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_gpt_clf_2.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAsfjV9rytVr"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "dm2Ik1eAytVr",
        "outputId": "82b519c1-0d24-4deb-94a5-33a6cd3c2db9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_gpt_clf_2, dev_set_labels_gpt_clf_2, dev_set_metrics_gpt_clf_2 = trainer_gpt_clf_2.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gAE3QYYytVr",
        "outputId": "ff98b0b7-d925-45f1-ad53-b8b7ea12643d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.3965911269187927,\n",
              " 'dev_accuracy': 0.9235912129894938,\n",
              " 'dev_f1': 0.550561797752809,\n",
              " 'dev_precision': 0.6242038216560509,\n",
              " 'dev_recall': 0.49246231155778897,\n",
              " 'dev_runtime': 10.5422,\n",
              " 'dev_samples_per_second': 198.631,\n",
              " 'dev_steps_per_second': 12.426}"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_gpt_clf_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "6lbZcv2OytVr"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_gpt_clf_2 = np.argmax(dev_set_preds_gpt_clf_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Foo6VyytVr"
      },
      "source": [
        "### Saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1jEVvBxytVr",
        "outputId": "db64e4f3-0477-4ae5-8b24-5b8335366152"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf_2_run2\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf_2_run2/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf_2_run2/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf_2_run2/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/deberta_frozen_gpt_clf_2_run2/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# save the best model\n",
        "trainer_gpt_clf_2.save_model(f'{results_folder}/deberta_frozen_gpt_clf_2_run2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLbPBatblEuX",
        "outputId": "c66bf9e6-c26e-427e-c72b-55eb3704ac82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file /content/drive/MyDrive/NLP/results/deberta_gpt/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/NLP/results/deberta_gpt\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/NLP/results/deberta_gpt/pytorch_model.bin\n",
            "Some weights of the model checkpoint at /content/drive/MyDrive/NLP/results/deberta_gpt were not used when initializing DebertaForSequenceClassification: ['classifier.4.bias', 'classifier.9.bias', 'classifier.1.running_var', 'classifier.0.bias', 'classifier.5.num_batches_tracked', 'classifier.5.bias', 'classifier.1.running_mean', 'classifier.9.running_var', 'classifier.1.num_batches_tracked', 'classifier.12.bias', 'classifier.1.weight', 'classifier.9.running_mean', 'classifier.5.running_var', 'classifier.0.weight', 'classifier.4.weight', 'classifier.8.bias', 'classifier.5.weight', 'classifier.9.weight', 'classifier.1.bias', 'classifier.8.weight', 'classifier.9.num_batches_tracked', 'classifier.12.weight', 'classifier.5.running_mean']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/results/deberta_gpt and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# ### Load trained model\n",
        "# trained_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     f'{results_folder}/deberta_gpt', \n",
        "#     num_labels=2, \n",
        "#     id2label=id2label, \n",
        "#     label2id=label2id\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z6arLEwQb0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9cR5EoWKQcgi"
      },
      "source": [
        "### FINAL MODEL: Train with best hyperparameters on the entire train dataset (train_train_aug + train_dev) - gradient accumulation step = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "RtNLhfNNU-QV"
      },
      "outputs": [],
      "source": [
        "pcl_df_train_train = pd.read_csv(f\"{data_folder}/pcl_df_train_train_preprocessed.csv\")\n",
        "pcl_df_train_train_aug = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug.csv\")\n",
        "pcl_df_train_train_gpt = pd.read_csv(f\"{data_folder}/pcl_df_train_train_aug_chatgpt.csv\")\n",
        "\n",
        "pcl_df_train_dev = pd.read_csv(f\"{data_folder}/pcl_df_train_dev_preprocessed.csv\")\n",
        "pcl_df_dev_pd = pd.read_csv(f\"{data_folder}/pcl_df_dev_preprocessed.csv\")\n",
        "\n",
        "\n",
        "pcl_df_train_pd = pd.concat(\n",
        "    [pcl_df_train_train_aug, pcl_df_train_dev], axis=0, ignore_index=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "ooK4bH8EiimP"
      },
      "outputs": [],
      "source": [
        "pcl_df_train = pcl_df_train_pd[['text', 'class']]\n",
        "pcl_df_dev = pcl_df_dev_pd[['text', 'class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "__hz0-w6fp9H"
      },
      "outputs": [],
      "source": [
        "pcl_df_train = datasets.Dataset.from_pandas(pcl_df_train)\n",
        "pcl_df_dev = datasets.Dataset.from_pandas(pcl_df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2b29f034c219420e869f994583853fc1",
            "370038cd976c42faa9236a6ce57514e6",
            "4fdbb9d4399d4b3fbaf0aed05209acbe",
            "c3e0152e6c0d42d3a2de8c2a47dc4d5f",
            "c654d54b885a4000b655fec3675a564e",
            "43d951c118e94273bba71603336de98f",
            "06a3486777a849d081d4f2ec2bc3f0a8",
            "4ed9b4c3ae0c4b618bd8bcd16fc4c771",
            "5b3a567ad28e4443a1ee09a6596c1521",
            "860785c887654ed89323adb4af7761a6",
            "a827f32e580a47bc9575fcfef8030c26",
            "f535e8ad5fe34044ae4de3552bc327a2",
            "b66ea38abe5d4f0d87bbf95a99a21595",
            "2d2ef3acd65a49268a8a1a01aef7603f",
            "764e5c25a3a84c588744bd7a8ae7adbf",
            "3191af636062416dbad2982520c52c34",
            "011c8811adb84f0c9ac9fb9574471ac8",
            "0406e562b8fe4902a2d9764bd894a6a6",
            "207d94f024ab44e2b982a72c807f2c5d",
            "0f76c6c7f81a4c06bdb3578a80b881ba",
            "f43b19b87f984ae38aa33a0dc659020e",
            "b27de9bd54a24e369877617078e25719"
          ]
        },
        "id": "RmGPfeUQfp_T",
        "outputId": "02741d4a-a15b-43a3-deb1-2f2e1ad08686"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b29f034c219420e869f994583853fc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8375 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f535e8ad5fe34044ae4de3552bc327a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2094 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pcl_df_train = pcl_df_train.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_train)\n",
        ")\n",
        "\n",
        "pcl_df_dev = pcl_df_dev.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_dev)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "RtY90VT1gO5e"
      },
      "outputs": [],
      "source": [
        "pcl_df_train.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")\n",
        "\n",
        "pcl_df_dev.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask', 'class']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "ZAiTeIE7gVHZ"
      },
      "outputs": [],
      "source": [
        "pcl_df_train = pcl_df_train.rename_column(\"class\", \"label\")\n",
        "pcl_df_dev = pcl_df_dev.rename_column(\"class\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "762S4YNeU8D2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "i0DrNzDLQcgj"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "# lr = best_learning_rate\n",
        "# weight_decay = best_weight_decay\n",
        "# train_batch_size = best_per_device_train_batch_size\n",
        "# warmup_steps = best_warmup_steps\n",
        "# eval_batch_size = 16\n",
        "# gradient_accumulation_steps = 8\n",
        "# logging_steps = 100\n",
        "\n",
        "lr = 2e-05\n",
        "weight_decay = 0.1\n",
        "train_batch_size = 16\n",
        "warmup_steps = 0\n",
        "eval_batch_size = 16\n",
        "gradient_accumulation_steps = 2\n",
        "logging_steps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQFwQc8UQcgj",
        "outputId": "356bdf3f-19ab-4df0-9f58-ffb6a139d95b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args_best = TrainingArguments(\n",
        "    output_dir = results_folder,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = train_batch_size,\n",
        "    learning_rate = lr,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,    \n",
        "    per_device_eval_batch_size= eval_batch_size,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = 'eval_f1',\n",
        "    greater_is_better = True,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    logging_steps = logging_steps,\n",
        "    fp16 = True,\n",
        "    logging_dir=logging_folder,\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'deberta-classification-final'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnQeP8pCQcgj",
        "outputId": "17479b17-7939-4f79-9769-f5c6cc514f26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer_best = Trainer(\n",
        "        args=training_args_best,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=pcl_df_train,\n",
        "        eval_dataset=pcl_df_dev,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "maUpDl1VQcgj",
        "outputId": "48fffb33-8d85-46fb-c8aa-ec385eaef2da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-base/snapshots/0d1b43ccf21b5acd9f4e5f7b077fa698f05cf195/pytorch_model.bin\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 8375\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 1310\n",
            "  Number of trainable parameters = 50983682\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1310' max='1310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1310/1310 11:04, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.228400</td>\n",
              "      <td>0.190793</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.605598</td>\n",
              "      <td>0.613402</td>\n",
              "      <td>0.597990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>0.180054</td>\n",
              "      <td>0.927412</td>\n",
              "      <td>0.621891</td>\n",
              "      <td>0.615764</td>\n",
              "      <td>0.628141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.135500</td>\n",
              "      <td>0.200687</td>\n",
              "      <td>0.917861</td>\n",
              "      <td>0.594340</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.633166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.106400</td>\n",
              "      <td>0.224061</td>\n",
              "      <td>0.917383</td>\n",
              "      <td>0.572840</td>\n",
              "      <td>0.563107</td>\n",
              "      <td>0.582915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.070900</td>\n",
              "      <td>0.252049</td>\n",
              "      <td>0.916428</td>\n",
              "      <td>0.563591</td>\n",
              "      <td>0.559406</td>\n",
              "      <td>0.567839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-262\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-262/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-262/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-262/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-262/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-524\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-524/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-524/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-524/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-524/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-786\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-786/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-786/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-786/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-786/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1048\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1048/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1048/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1048/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1048/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/results/checkpoint-1310\n",
            "Configuration saved in /content/drive/MyDrive/NLP/results/checkpoint-1310/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/results/checkpoint-1310/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/NLP/results/checkpoint-1310/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/NLP/results/checkpoint-1310/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/NLP/results/checkpoint-524 (score: 0.6218905472636815).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1310, training_loss=0.14853475803637323, metrics={'train_runtime': 664.7676, 'train_samples_per_second': 62.992, 'train_steps_per_second': 1.971, 'total_flos': 1.283877446784e+16, 'train_loss': 0.14853475803637323, 'epoch': 5.0})"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_best.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "t8qrI3-qQcgj",
        "outputId": "0ceb8cac-23b3-4189-c0b9-a1ecf042444e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [131/131 00:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.1800541877746582,\n",
              " 'eval_accuracy': 0.9274116523400191,\n",
              " 'eval_f1': 0.6218905472636815,\n",
              " 'eval_precision': 0.6157635467980296,\n",
              " 'eval_recall': 0.628140703517588,\n",
              " 'eval_runtime': 10.4412,\n",
              " 'eval_samples_per_second': 200.552,\n",
              " 'eval_steps_per_second': 12.546,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model on eval_dataset=pcl_df_train_dev, this should give the \n",
        "# best performance found during the training process\n",
        "trainer_best.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nha_2UtiQcgk"
      },
      "source": [
        "### Make predictions on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "3lJNPQvaQcgk",
        "outputId": "0fcd2dcd-5592-47d8-e1d1-4be5e82d8e67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2094\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dev_set_preds_final, dev_set_labels_final, dev_set_metrics_final = trainer_best.predict(\n",
        "    pcl_df_dev, metric_key_prefix=\"dev\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NRgrjkoQcgk",
        "outputId": "bf3ffcd8-d61a-4641-b244-e80b130ba894"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dev_loss': 0.1800541877746582,\n",
              " 'dev_accuracy': 0.9274116523400191,\n",
              " 'dev_f1': 0.6218905472636815,\n",
              " 'dev_precision': 0.6157635467980296,\n",
              " 'dev_recall': 0.628140703517588,\n",
              " 'dev_runtime': 10.5266,\n",
              " 'dev_samples_per_second': 198.925,\n",
              " 'dev_steps_per_second': 12.445}"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_metrics_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCDFwEvAlshz",
        "outputId": "d991dbd2-a9c8-496e-a85d-e3ca0f3b04b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.739 , -0.727 ],\n",
              "       [ 1.629 , -1.75  ],\n",
              "       [ 0.485 , -0.5283],\n",
              "       ...,\n",
              "       [ 1.041 , -1.13  ],\n",
              "       [ 2.074 , -2.096 ],\n",
              "       [-0.9194,  1.135 ]], dtype=float16)"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_preds_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "iPJdJyReQcgk"
      },
      "outputs": [],
      "source": [
        "dev_set_pred_labels_final = np.argmax(dev_set_preds_final, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RegesIMmBfY",
        "outputId": "62657bc8-d64c-436c-8053-e77430146d7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2094,)"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_set_pred_labels_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os9mf7qGlpnP",
        "outputId": "ba74b365-726e-44ae-ef99-31918321cec9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2094, 9)"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_dev_pd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "dWpPub8ZmIEm"
      },
      "outputs": [],
      "source": [
        "pcl_df_dev_pd[\"pred_class\"] = dev_set_pred_labels_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPEXoBti3st1",
        "outputId": "6521a8e4-aff7-44a7-fa9e-d29e394df8d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "par_id               0\n",
              "art_id               0\n",
              "keyword              0\n",
              "country_code         0\n",
              "text                 0\n",
              "label                0\n",
              "class                0\n",
              "preprocessed_text    0\n",
              "len_text             0\n",
              "pred_class           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_dev_pd.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "mClX-ifi8LhL"
      },
      "outputs": [],
      "source": [
        "pcl_df_dev_pd.to_csv(f\"{results_folder}/pcl_df_dev_w_preds.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8q1E4TNuYov"
      },
      "source": [
        "### Make predictions on the official test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "2epTq_GPubl7"
      },
      "outputs": [],
      "source": [
        "pcl_df_test_pd = pd.read_csv(f\"{data_folder}/pcl_df_test_preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-6QZqUvuzqr",
        "outputId": "cb3177f2-9cf7-4939-a847-338df1386e92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['par_id', 'art_id', 'keyword', 'country_code', 'text'], dtype='object')"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcl_df_test_pd.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "JstUHsfxuwzE"
      },
      "outputs": [],
      "source": [
        "pcl_df_test = pcl_df_test_pd[['text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "b9srly63uwzF"
      },
      "outputs": [],
      "source": [
        "pcl_df_test = datasets.Dataset.from_pandas(pcl_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "daf1cb8daf464343ae759817e5b19e46",
            "5173e983bf854c81b13c4d0b6f965d2b",
            "c33ae87bf99f4d3884a80af3db7adac8",
            "df7a13ef2b6d4a77ac6c4a7dd42424a4",
            "d793ede970fb4a7f95116a57f31f9d14",
            "417aad5515394cf7a3d60fb5649d23ac",
            "37c527192d5540dfac6e5dd2047503ae",
            "914337a8579d42efb585bb09effcfc53",
            "356c9e5774bd4bf9a7159c8a7b1866e9",
            "9294dc3a5f1d4cd0bc22e8126c691973",
            "acfd3841b53e412c864a7bd892b38949"
          ]
        },
        "id": "2ra-KcyeuwzF",
        "outputId": "92313704-2b93-4c57-e998-c1e5fcd8c8d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "daf1cb8daf464343ae759817e5b19e46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pcl_df_test = pcl_df_test.map(\n",
        "    tokenization, batched = True, batch_size = len(pcl_df_test)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "gh09HJLduwzF"
      },
      "outputs": [],
      "source": [
        "pcl_df_test.set_format(\n",
        "    'torch', columns=['input_ids', 'attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "S2dm0jZGupSF",
        "outputId": "17bdcc79-f5e7-4b16-ffef-aa731ffcef84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 3832\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_set_preds_final, test_set_labels_final, test_set_metrics_final = trainer_best.predict(\n",
        "    pcl_df_test, metric_key_prefix=\"test\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmeSL9pywdYO",
        "outputId": "0c651750-6ede-4f4f-bd38-4972262274fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_runtime': 18.6207,\n",
              " 'test_samples_per_second': 205.792,\n",
              " 'test_steps_per_second': 12.889}"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_metrics_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co67_UgVwdYP",
        "outputId": "f8293a2f-9605-4bb8-c163-d1f5da74d89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.854, -3.26 ],\n",
              "       [ 0.478, -0.598],\n",
              "       [ 2.295, -2.469],\n",
              "       ...,\n",
              "       [ 2.564, -2.74 ],\n",
              "       [ 2.098, -2.209],\n",
              "       [ 1.189, -1.275]], dtype=float16)"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_preds_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "KQWjEZ5GwdYP"
      },
      "outputs": [],
      "source": [
        "test_set_pred_labels_final = np.argmax(test_set_preds_final, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EyDSgKtwdYP",
        "outputId": "9058d42a-aa3e-492b-a234-b5fbeddd018b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3832,)"
            ]
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_pred_labels_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzJk03LTwc7I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ERVqlJ0pWIf"
      },
      "source": [
        "### Save predicted labels on dev set and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "2yJ9qrNHmIJ5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.savetxt(f\"{results_folder}/dev.txt\", dev_set_pred_labels_final)\n",
        "np.savetxt(f\"{results_folder}/test.txt\", test_set_pred_labels_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_i5a0TQQbfk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00f3c969c0ab4ae581a0c85a6d4f8f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39df6318ac8d4f259db9eda9d6cde5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_0176f0bb8c554425ac51860f2c3a1254",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "011c8811adb84f0c9ac9fb9574471ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0176f0bb8c554425ac51860f2c3a1254": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "024cbaea6a1a46e9a9fbf24eb7ce7134": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0406e562b8fe4902a2d9764bd894a6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a3486777a849d081d4f2ec2bc3f0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08df0af217df4183aeb7ad56e798c91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac0a38343a54ea29c70412ec954ccb1",
            "placeholder": "​",
            "style": "IPY_MODEL_a55bc13378544e07821e26ccfd885f86",
            "value": " 12150/12150 [00:10&lt;00:00, 1168.15 examples/s]"
          }
        },
        "0db2b24f343948d4b6b1a4d6c0cd343a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f5d74520fa849d0a03a6d0d1d1b9663": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f76c6c7f81a4c06bdb3578a80b881ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10a14da24efc43cbac37aa949da1e9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1188130d17cc425082260490e10ecdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23271b5a30404bda943229099ea6125b",
            "placeholder": "​",
            "style": "IPY_MODEL_5c0b3fd0247e49f3a23b7119775216db",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "1327754c2f9c46fcbb423ed2662ab26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71d6650fff54fac979d1ff2f2685cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_548c37fbaacf43148f3f18e85498dda1",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "1713341ac794472c92874501d1f57956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3134010d2274a9a847f545b46b083a1",
            "max": 898825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86caa214a7f6463d96b54ca4ef51254d",
            "value": 898825
          }
        },
        "18681bc17a8c478faaa20813ca0459f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a0e82a332b149808c82363ae1c2320d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c36b9d9cac743e09b7e1a29d556a092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fbc4a2075304686bcb02d0da564c74f",
            "max": 1675,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b79acb1e4e141729562ce800c45687a",
            "value": 1675
          }
        },
        "207d94f024ab44e2b982a72c807f2c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d48767fc7a4ec29892f5378fea1fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367a0a40d4a54fe5ae36854d5854ca10",
            "placeholder": "​",
            "style": "IPY_MODEL_e960c4141bbd4d7dbd4fb435828e60a7",
            "value": " 13983/13983 [00:12&lt;00:00, 1157.95 examples/s]"
          }
        },
        "22e2701a5f514e91bffa750e864c07da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10a14da24efc43cbac37aa949da1e9e2",
            "max": 6700,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ab09964ddf84901a4e8eeed7dd5fc15",
            "value": 6700
          }
        },
        "2300bb7abd7d4c109a9efd2839ba51fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9aaf8e17cb647a3888a0ec597c2d66a",
            "placeholder": "​",
            "style": "IPY_MODEL_1a0e82a332b149808c82363ae1c2320d",
            "value": " 899k/899k [00:00&lt;00:00, 6.72MB/s]"
          }
        },
        "2320de8dada14694872ddff55d6e71d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_794b1b17d1c24b81bef19067acbb0e5e",
            "placeholder": "​",
            "style": "IPY_MODEL_dda2651ccc444d08bb6988d4354c58b3",
            "value": " 2094/2094 [00:01&lt;00:00, 1111.87 examples/s]"
          }
        },
        "23271b5a30404bda943229099ea6125b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23faab8cd4724763933cbaff7e69c677": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252e7be1a1b14831ba1fdb24d77c6e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c770cf164c1b4517af3a5bbdb3aa6b48",
            "placeholder": "​",
            "style": "IPY_MODEL_c986e7caee3b4afebf15e48626146d24",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "28fd670ba08d438d9496dee5afbbdb79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2b29f034c219420e869f994583853fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_370038cd976c42faa9236a6ce57514e6",
              "IPY_MODEL_4fdbb9d4399d4b3fbaf0aed05209acbe",
              "IPY_MODEL_c3e0152e6c0d42d3a2de8c2a47dc4d5f"
            ],
            "layout": "IPY_MODEL_c654d54b885a4000b655fec3675a564e"
          }
        },
        "2bff2c437ee94994b7de483b9059254f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2ef3acd65a49268a8a1a01aef7603f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207d94f024ab44e2b982a72c807f2c5d",
            "max": 2094,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f76c6c7f81a4c06bdb3578a80b881ba",
            "value": 2094
          }
        },
        "3191af636062416dbad2982520c52c34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3319484db3f648aaa2d2059c7214cdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "356c9e5774bd4bf9a7159c8a7b1866e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "367a0a40d4a54fe5ae36854d5854ca10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36cecacaf8e249648c1d3c25d3057749": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_252e7be1a1b14831ba1fdb24d77c6e1c",
              "IPY_MODEL_dff1c2a67b154993a7ff0cb4db3a7646",
              "IPY_MODEL_8315800528eb4955af3fdf13d40e70e2"
            ],
            "layout": "IPY_MODEL_3f84c98e13bc4018a667c33ac1e8a6b9"
          }
        },
        "370038cd976c42faa9236a6ce57514e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d951c118e94273bba71603336de98f",
            "placeholder": "​",
            "style": "IPY_MODEL_06a3486777a849d081d4f2ec2bc3f0a8",
            "value": "Map: 100%"
          }
        },
        "371257f55f654b06bdde97f16e3c651d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "37c527192d5540dfac6e5dd2047503ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "393e36bf70da41f0bd7a06a86c188b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39df6318ac8d4f259db9eda9d6cde5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac1d594568147eca00b0ee7837b2040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7f686288c2d4f72af66fc93022add71",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb5eb037c9e4840a3658d023442b07c",
            "value": " 456k/456k [00:00&lt;00:00, 3.32MB/s]"
          }
        },
        "3f03232b381d495eb4203a969ad3636c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f84c98e13bc4018a667c33ac1e8a6b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fadcee66dee4ed281358fe8158d6128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1428cf1309b4ef293c7c5ac9df69fa4",
            "max": 12150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0db2b24f343948d4b6b1a4d6c0cd343a",
            "value": 12150
          }
        },
        "417aad5515394cf7a3d60fb5649d23ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d951c118e94273bba71603336de98f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4832c645c2794bf4af9bab4c0e8df11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1327754c2f9c46fcbb423ed2662ab26d",
              "IPY_MODEL_e4fc70b897714adf89258b6149e67995",
              "IPY_MODEL_3ac1d594568147eca00b0ee7837b2040"
            ],
            "layout": "IPY_MODEL_0f5d74520fa849d0a03a6d0d1d1b9663"
          }
        },
        "499fdeaeb0be4cffae0653b1a519d134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ab09964ddf84901a4e8eeed7dd5fc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ed9b4c3ae0c4b618bd8bcd16fc4c771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fdbb9d4399d4b3fbaf0aed05209acbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed9b4c3ae0c4b618bd8bcd16fc4c771",
            "max": 8375,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b3a567ad28e4443a1ee09a6596c1521",
            "value": 8375
          }
        },
        "5173e983bf854c81b13c4d0b6f965d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417aad5515394cf7a3d60fb5649d23ac",
            "placeholder": "​",
            "style": "IPY_MODEL_37c527192d5540dfac6e5dd2047503ae",
            "value": "Map: 100%"
          }
        },
        "548c37fbaacf43148f3f18e85498dda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5567c2c7c75741019876efd10c5be80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b176d3bccc94fa6a27b2c91b5e6f416",
            "placeholder": "​",
            "style": "IPY_MODEL_ac2f5851ec60469b90b4c3e41e4bc5bb",
            "value": "Map: 100%"
          }
        },
        "58383934b54c41ce9cd931024b91dce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024cbaea6a1a46e9a9fbf24eb7ce7134",
            "placeholder": "​",
            "style": "IPY_MODEL_393e36bf70da41f0bd7a06a86c188b05",
            "value": "Map: 100%"
          }
        },
        "5a29b2d6d2c84dd4b8d926ddcc6eefd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a7aad6d1e1645a4a4d25173b7f5a3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1188130d17cc425082260490e10ecdf5",
              "IPY_MODEL_cb7f9eee64bc4dfbad8a372ff755350e",
              "IPY_MODEL_fcfcf1f263e247988a567b60b5e00b92"
            ],
            "layout": "IPY_MODEL_a2810b6628ce4f42a0ec5a020e7f1a97"
          }
        },
        "5b176d3bccc94fa6a27b2c91b5e6f416": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3a567ad28e4443a1ee09a6596c1521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b79acb1e4e141729562ce800c45687a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c0b3fd0247e49f3a23b7119775216db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f6aa9255c84d86a6c2e7e3f410e6e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d31333714634fd1afce4a16c4e96a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23faab8cd4724763933cbaff7e69c677",
            "max": 13983,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4e47987a2c34878ad5d846a83aa7b38",
            "value": 13983
          }
        },
        "6dfb5d3dad534573a50919dd8d7322ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb5eb037c9e4840a3658d023442b07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75efdb1bf9924cefbb412aabc1017ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e54ffdd5dd2c436d9ccb4e0b67d5ce63",
            "placeholder": "​",
            "style": "IPY_MODEL_e9f2ca96c21349e5ad812db940138e9f",
            "value": "Map: 100%"
          }
        },
        "764e5c25a3a84c588744bd7a8ae7adbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43b19b87f984ae38aa33a0dc659020e",
            "placeholder": "​",
            "style": "IPY_MODEL_b27de9bd54a24e369877617078e25719",
            "value": " 2094/2094 [00:01&lt;00:00, 1237.27 examples/s]"
          }
        },
        "794b1b17d1c24b81bef19067acbb0e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "795be488d30948cfb552461017252dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a29b2d6d2c84dd4b8d926ddcc6eefd6",
            "placeholder": "​",
            "style": "IPY_MODEL_c94c0ea531ba424abd3a8c4eaeb6c6e9",
            "value": " 1675/1675 [00:01&lt;00:00, 1122.09 examples/s]"
          }
        },
        "7b5be1ab8aec4b838f7b9860d7582cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5567c2c7c75741019876efd10c5be80f",
              "IPY_MODEL_e930f151724e44349552ba3c10f0e88f",
              "IPY_MODEL_2320de8dada14694872ddff55d6e71d8"
            ],
            "layout": "IPY_MODEL_ce7abf16161e40d1977058b16fa836af"
          }
        },
        "7fbc4a2075304686bcb02d0da564c74f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8315800528eb4955af3fdf13d40e70e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4eae702ae2b410691a3e9bca12d3a25",
            "placeholder": "​",
            "style": "IPY_MODEL_3f03232b381d495eb4203a969ad3636c",
            "value": " 52.0/52.0 [00:00&lt;00:00, 1.86kB/s]"
          }
        },
        "854c6d4cecd94c10b6031ff0d1866126": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecaaf6fe83564f25bc21b9c880455767",
            "placeholder": "​",
            "style": "IPY_MODEL_e02a5770175440da97981c4871f306aa",
            "value": " 474/474 [00:00&lt;00:00, 29.1kB/s]"
          }
        },
        "860785c887654ed89323adb4af7761a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86caa214a7f6463d96b54ca4ef51254d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8beffbfe6b1b4f489e848fa3b68eef9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "914337a8579d42efb585bb09effcfc53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920b3c9577a74feaa8a88d055a3380e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9294dc3a5f1d4cd0bc22e8126c691973": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966a697e8da64798abf7c1e3c84598fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dfb5d3dad534573a50919dd8d7322ca",
            "max": 474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea763c88e38a46a7b049f879b08d078d",
            "value": 474
          }
        },
        "9aa2dcaa4d8a47b3b599223cee557894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d5990e616974dffae1ed3b54d066e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a84bbfa0f3b7404682ac7dd6d8afc601",
            "placeholder": "​",
            "style": "IPY_MODEL_18681bc17a8c478faaa20813ca0459f2",
            "value": "Map: 100%"
          }
        },
        "9e7c9ddc9cda428982c885fd906f1332": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf8baed112804f98870543e1f7b0cafe",
              "IPY_MODEL_1c36b9d9cac743e09b7e1a29d556a092",
              "IPY_MODEL_795be488d30948cfb552461017252dee"
            ],
            "layout": "IPY_MODEL_f9a68aa823b44619995be54c5e9fb446"
          }
        },
        "a1cf889ac11a4f8296a45274aefb22f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2810b6628ce4f42a0ec5a020e7f1a97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cc98ab9aa04a618a6ad7a6b3cb9b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4eae702ae2b410691a3e9bca12d3a25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55bc13378544e07821e26ccfd885f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a71d6650fff54fac979d1ff2f2685cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a827f32e580a47bc9575fcfef8030c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a84bbfa0f3b7404682ac7dd6d8afc601": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac0a38343a54ea29c70412ec954ccb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab814e7ed4dc45b28a5cfd0cbbe91598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac2f5851ec60469b90b4c3e41e4bc5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acfd3841b53e412c864a7bd892b38949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "addc7c801af64ce285e9eba9f94fa1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec4f878fb27045e8b778d996ae7b721e",
              "IPY_MODEL_1713341ac794472c92874501d1f57956",
              "IPY_MODEL_2300bb7abd7d4c109a9efd2839ba51fe"
            ],
            "layout": "IPY_MODEL_c75c08ff256d40039a8a0f7a0b9c560c"
          }
        },
        "b1f4ecb8da1c4f5ab76e81d9b22b619a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58383934b54c41ce9cd931024b91dce3",
              "IPY_MODEL_22e2701a5f514e91bffa750e864c07da",
              "IPY_MODEL_b62268aef07c41508c6d84cf6792a1fd"
            ],
            "layout": "IPY_MODEL_371257f55f654b06bdde97f16e3c651d"
          }
        },
        "b27de9bd54a24e369877617078e25719": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b62268aef07c41508c6d84cf6792a1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bff2c437ee94994b7de483b9059254f",
            "placeholder": "​",
            "style": "IPY_MODEL_f57af91095984ea4a4f6d2e99be1ced0",
            "value": " 6700/6700 [00:07&lt;00:00, 907.39 examples/s]"
          }
        },
        "b66ea38abe5d4f0d87bbf95a99a21595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011c8811adb84f0c9ac9fb9574471ac8",
            "placeholder": "​",
            "style": "IPY_MODEL_0406e562b8fe4902a2d9764bd894a6a6",
            "value": "Map: 100%"
          }
        },
        "bd88bc63467749a5a0fff8daedd873ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8baed112804f98870543e1f7b0cafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd88bc63467749a5a0fff8daedd873ec",
            "placeholder": "​",
            "style": "IPY_MODEL_3319484db3f648aaa2d2059c7214cdbd",
            "value": "Map: 100%"
          }
        },
        "c33ae87bf99f4d3884a80af3db7adac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_914337a8579d42efb585bb09effcfc53",
            "max": 3832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_356c9e5774bd4bf9a7159c8a7b1866e9",
            "value": 3832
          }
        },
        "c3a79f60f3094866b6b2b261203fe60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00f3c969c0ab4ae581a0c85a6d4f8f49",
              "IPY_MODEL_966a697e8da64798abf7c1e3c84598fc",
              "IPY_MODEL_854c6d4cecd94c10b6031ff0d1866126"
            ],
            "layout": "IPY_MODEL_a1cf889ac11a4f8296a45274aefb22f7"
          }
        },
        "c3e0152e6c0d42d3a2de8c2a47dc4d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860785c887654ed89323adb4af7761a6",
            "placeholder": "​",
            "style": "IPY_MODEL_a827f32e580a47bc9575fcfef8030c26",
            "value": " 8375/8375 [00:07&lt;00:00, 1174.37 examples/s]"
          }
        },
        "c5bc4d8fb0a24a778858dfb2f43ffb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c654d54b885a4000b655fec3675a564e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c75c08ff256d40039a8a0f7a0b9c560c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c770cf164c1b4517af3a5bbdb3aa6b48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f686288c2d4f72af66fc93022add71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94c0ea531ba424abd3a8c4eaeb6c6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c986e7caee3b4afebf15e48626146d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb7f9eee64bc4dfbad8a372ff755350e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7773de624f4714b181d95dc880a821",
            "max": 558614189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fab9a220eba648df890362973b48b0da",
            "value": 558614189
          }
        },
        "cd45171b319b437294c8d181aaf71489": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7abf16161e40d1977058b16fa836af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "cfe3ae963a904619862d4437e072ac60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75efdb1bf9924cefbb412aabc1017ab4",
              "IPY_MODEL_3fadcee66dee4ed281358fe8158d6128",
              "IPY_MODEL_08df0af217df4183aeb7ad56e798c91f"
            ],
            "layout": "IPY_MODEL_28fd670ba08d438d9496dee5afbbdb79"
          }
        },
        "d02ad016111b45ff8f57a3ce078837b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e47987a2c34878ad5d846a83aa7b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d793ede970fb4a7f95116a57f31f9d14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "daf1cb8daf464343ae759817e5b19e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5173e983bf854c81b13c4d0b6f965d2b",
              "IPY_MODEL_c33ae87bf99f4d3884a80af3db7adac8",
              "IPY_MODEL_df7a13ef2b6d4a77ac6c4a7dd42424a4"
            ],
            "layout": "IPY_MODEL_d793ede970fb4a7f95116a57f31f9d14"
          }
        },
        "dda2651ccc444d08bb6988d4354c58b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb29e6807d949659bd07f84d84beb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d5990e616974dffae1ed3b54d066e82",
              "IPY_MODEL_6d31333714634fd1afce4a16c4e96a1d",
              "IPY_MODEL_21d48767fc7a4ec29892f5378fea1fb5"
            ],
            "layout": "IPY_MODEL_8beffbfe6b1b4f489e848fa3b68eef9b"
          }
        },
        "de7773de624f4714b181d95dc880a821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7a13ef2b6d4a77ac6c4a7dd42424a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9294dc3a5f1d4cd0bc22e8126c691973",
            "placeholder": "​",
            "style": "IPY_MODEL_acfd3841b53e412c864a7bd892b38949",
            "value": " 3832/3832 [00:03&lt;00:00, 1114.51 examples/s]"
          }
        },
        "dff1c2a67b154993a7ff0cb4db3a7646": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e81177d036c14e1a85cc46c63cb008cc",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4cc98ab9aa04a618a6ad7a6b3cb9b91",
            "value": 52
          }
        },
        "e02a5770175440da97981c4871f306aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1428cf1309b4ef293c7c5ac9df69fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3134010d2274a9a847f545b46b083a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4fc70b897714adf89258b6149e67995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f6aa9255c84d86a6c2e7e3f410e6e5",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab814e7ed4dc45b28a5cfd0cbbe91598",
            "value": 456318
          }
        },
        "e54ffdd5dd2c436d9ccb4e0b67d5ce63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81177d036c14e1a85cc46c63cb008cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e930f151724e44349552ba3c10f0e88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d02ad016111b45ff8f57a3ce078837b1",
            "max": 2094,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5bc4d8fb0a24a778858dfb2f43ffb67",
            "value": 2094
          }
        },
        "e960c4141bbd4d7dbd4fb435828e60a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9f2ca96c21349e5ad812db940138e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea763c88e38a46a7b049f879b08d078d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec4f878fb27045e8b778d996ae7b721e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd45171b319b437294c8d181aaf71489",
            "placeholder": "​",
            "style": "IPY_MODEL_9aa2dcaa4d8a47b3b599223cee557894",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "ecaaf6fe83564f25bc21b9c880455767": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43b19b87f984ae38aa33a0dc659020e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f535e8ad5fe34044ae4de3552bc327a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b66ea38abe5d4f0d87bbf95a99a21595",
              "IPY_MODEL_2d2ef3acd65a49268a8a1a01aef7603f",
              "IPY_MODEL_764e5c25a3a84c588744bd7a8ae7adbf"
            ],
            "layout": "IPY_MODEL_3191af636062416dbad2982520c52c34"
          }
        },
        "f57af91095984ea4a4f6d2e99be1ced0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a68aa823b44619995be54c5e9fb446": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f9aaf8e17cb647a3888a0ec597c2d66a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab9a220eba648df890362973b48b0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcfcf1f263e247988a567b60b5e00b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_920b3c9577a74feaa8a88d055a3380e4",
            "placeholder": "​",
            "style": "IPY_MODEL_499fdeaeb0be4cffae0653b1a519d134",
            "value": " 559M/559M [00:05&lt;00:00, 101MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
